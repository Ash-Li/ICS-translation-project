1
00:00:00,000 --> 00:00:06,779
good afternoon everyone welcome to 213

2
00:00:03,024 --> 00:00:10,543
it's good to see you just a reminder

3
00:00:06,779 --> 00:00:13,844
that your attack lab is due tonight at

4
00:00:10,759 --> 00:00:18,180
11:59 p.m. you have one great day for

5
00:00:14,429 --> 00:00:21,431
this for this lab and cache lab we'll go

6
00:00:18,018 --> 00:00:22,089
out and write about the same time now

7
00:00:21,449 --> 00:00:27,150
it's going to be a little tight for cash

8
00:00:22,089 --> 00:00:27,156
lab it'll be due next Thursday so you

9
00:00:27,015 --> 00:00:33,084
might want to you might want to get

10
00:00:28,056 --> 00:00:34,985
started on that soon b2 last lecture we

11
00:00:33,084 --> 00:00:37,116
learned about the memory hierarchy and

12
00:00:35,489 --> 00:00:42,440
the idea of caching today we're going to

13
00:00:38,016 --> 00:00:45,395
look at a very important kind of cache

14
00:00:42,044 --> 00:00:48,683
which is a which are called cache

15
00:00:45,539 --> 00:00:50,550
memories and they're very important to

16
00:00:49,079 --> 00:00:52,050
you as a programmer because they can

17
00:00:50,055 --> 00:00:53,127
have such a big impact on the

18
00:00:52,005 --> 00:00:56,016
performance of your program so if you

19
00:00:54,027 --> 00:00:59,156
know about the existence of these cache

20
00:00:56,016 --> 00:01:00,485
memories and you know how they work as a

21
00:00:59,399 --> 00:01:04,010
programmer you'll be able to take

22
00:01:00,629 --> 00:01:04,010
advantage of that in your programs

23
00:01:07,051 --> 00:01:12,095
so last time we looked at that the

24
00:01:10,073 --> 00:01:19,135
memory hierarchy is a collection of

25
00:01:12,095 --> 00:01:19,099
storage devices with smaller costlier

26
00:01:20,059 --> 00:01:28,061
devices that the and faster devices at

27
00:01:23,021 --> 00:01:31,021
the top and slower cheaper and much

28
00:01:28,079 --> 00:01:34,120
larger devices at the at the bottom and

29
00:01:31,021 --> 00:01:37,097
then at each level in this hierarchy a

30
00:01:35,002 --> 00:01:42,025
the device that level K serves as a

31
00:01:37,097 --> 00:01:44,189
cache holds a subset of the blocks of

32
00:01:42,043 --> 00:01:52,052
that are contained in the device at the

33
00:01:45,089 --> 00:01:54,095
lower level at level K plus-1 now recall

34
00:01:52,052 --> 00:01:58,088
the general idea of caching so we have a

35
00:01:54,095 --> 00:01:59,174
memory array of bytes and it's it's we

36
00:01:58,088 --> 00:02:05,107
break it up arbitrarily into a

37
00:02:00,074 --> 00:02:07,543
collection of blocks and these this

38
00:02:05,899 --> 00:02:12,140
memory is larger slower and cheaper and

39
00:02:08,209 --> 00:02:14,218
so it's and it's much larger than a

40
00:02:12,014 --> 00:02:17,018
cache which is smaller faster and more

41
00:02:14,299 --> 00:02:18,304
expensive and which holds and which

42
00:02:17,018 --> 00:02:22,085
holds a subset of the blocks that are

43
00:02:18,799 --> 00:02:23,896
contained in the main memory and then

44
00:02:22,085 --> 00:02:25,178
blocks are copied back and forth between

45
00:02:24,769 --> 00:02:29,660
the cache in the memory in these block

46
00:02:26,078 --> 00:02:32,120
size transfer units so for example if

47
00:02:29,066 --> 00:02:38,425
our program requests a word that's been

48
00:02:33,002 --> 00:02:41,006
contained in block number 4 it asks the

49
00:02:39,019 --> 00:02:44,150
cache to to sent to return the word

50
00:02:41,006 --> 00:02:45,895
that's contained in block 4 the cache

51
00:02:44,015 --> 00:02:47,114
looks and it's at the blocks that it's

52
00:02:46,489 --> 00:02:50,810
the subset of the blocks that it's

53
00:02:48,014 --> 00:02:53,048
towards discovers that block 4 is not

54
00:02:50,081 --> 00:02:56,135
there so it asks the main memory to send

55
00:02:53,048 --> 00:02:58,085
it block 4 which it does and I and then

56
00:02:57,035 --> 00:03:02,060
when it when that block arrives at the

57
00:02:58,085 --> 00:03:03,163
cache the cache stores if it potentially

58
00:03:02,006 --> 00:03:07,007
overwriting some existing block

59
00:03:04,063 --> 00:03:09,068
similarly if if our program asks for a

60
00:03:07,007 --> 00:03:12,044
data word if that's contained within

61
00:03:09,068 --> 00:03:14,150
block 10 the cache looks sees that it

62
00:03:13,007 --> 00:03:18,029
doesn't have that block so it requests

63
00:03:15,005 --> 00:03:19,324
that block from memory which copies it

64
00:03:18,029 --> 00:03:23,048
into the cache

65
00:03:19,819 --> 00:03:27,260
which overwrites an existing block now

66
00:03:23,048 --> 00:03:29,947
subsequently if if our program asks for

67
00:03:27,026 --> 00:03:32,455
a request or if our program references a

68
00:03:30,379 --> 00:03:35,440
word that's contained in block 10 for

69
00:03:32,689 --> 00:03:38,150
example then the cache then we have a

70
00:03:35,989 --> 00:03:40,078
hit and the cache can return that block

71
00:03:38,015 --> 00:03:43,024
immediately without going to the

72
00:03:40,879 --> 00:03:49,930
expensive operation of contacting memory

73
00:03:43,159 --> 00:03:51,950
and fetching that block from memory now

74
00:03:50,389 --> 00:03:54,290
there's a very important class of

75
00:03:51,095 --> 00:03:57,334
thought of caches these so called cache

76
00:03:54,029 --> 00:04:00,928
memories which are contained in the CPU

77
00:03:58,189 --> 00:04:03,202
chip itself and are managed completely

78
00:04:01,189 --> 00:04:08,150
by Hardware and they're implemented

79
00:04:03,319 --> 00:04:10,730
using fast SRAM memories and the idea

80
00:04:08,015 --> 00:04:14,464
for this cache which is is right next to

81
00:04:10,073 --> 00:04:16,109
the register file is to hold frequently

82
00:04:14,599 --> 00:04:19,190
access blocks or blocks from main memory

83
00:04:17,009 --> 00:04:21,014
that are accessed frequently okay so

84
00:04:19,019 --> 00:04:25,618
hopefully because of the principle of

85
00:04:21,059 --> 00:04:28,061
locality most of our requests for data

86
00:04:25,789 --> 00:04:31,940
will actually be served out of this

87
00:04:28,061 --> 00:04:33,134
cache memory in a few cycles rather than

88
00:04:31,094 --> 00:04:36,112
in this set rather than from this slow

89
00:04:34,034 --> 00:04:36,112
main memory

90
00:04:39,046 --> 00:04:44,755
now cache memories are managed

91
00:04:41,069 --> 00:04:47,075
completely in Hardware so this means

92
00:04:45,169 --> 00:04:50,150
that the heart there's there has to be

93
00:04:47,075 --> 00:04:52,079
Hardware logic that knows how to look

94
00:04:50,015 --> 00:04:54,074
for blocks in the cache and determine

95
00:04:53,015 --> 00:04:57,214
whether or not a particular block is

96
00:04:54,074 --> 00:04:58,873
contained there so cache memories are

97
00:04:57,349 --> 00:05:01,970
have to be organized in a very kind of

98
00:04:59,539 --> 00:05:04,570
strict simple way so that the logic the

99
00:05:01,097 --> 00:05:06,194
lookup logic can be pretty simple so

100
00:05:04,849 --> 00:05:12,050
this is very all cache memories are

101
00:05:07,094 --> 00:05:13,753
organized in the following way you can

102
00:05:12,005 --> 00:05:19,063
think of that you can think of the cache

103
00:05:14,599 --> 00:05:19,630
as an array of s equals to the s sets

104
00:05:19,919 --> 00:05:25,984
each set consists of e to the to e lines

105
00:05:27,077 --> 00:05:38,102
where each line consists of a block of D

106
00:05:33,003 --> 00:05:43,982
it equals 2 to the D bytes of data a

107
00:05:39,002 --> 00:05:46,071
valid bit which indicates whether these

108
00:05:44,279 --> 00:05:47,345
these data bits are actually the bits

109
00:05:46,071 --> 00:05:49,460
and the data block are actually

110
00:05:47,939 --> 00:05:52,110
meaningful right it's possible they

111
00:05:50,099 --> 00:05:53,140
could just be random bits like you know

112
00:05:52,011 --> 00:05:56,540
when you first turn on the machine

113
00:05:53,509 --> 00:05:58,650
there's nothing in the cache but those

114
00:05:56,639 --> 00:05:59,642
bits will have values right the ability

115
00:05:58,065 --> 00:06:01,137
to be ones or zeros but they won't

116
00:05:59,939 --> 00:06:05,400
actually correspond to data okay so the

117
00:06:02,037 --> 00:06:08,133
valid bit tells us if these if these be

118
00:06:05,004 --> 00:06:10,095
fights actually mean anything and then

119
00:06:09,033 --> 00:06:14,522
there's some additional bits called the

120
00:06:11,031 --> 00:06:16,049
tag bits which will help us search for

121
00:06:14,819 --> 00:06:18,823
blocks which I'll show you in a minute

122
00:06:16,049 --> 00:06:22,131
now when we talk about our cache size

123
00:06:19,219 --> 00:06:27,080
we're referring to the number of data

124
00:06:23,031 --> 00:06:32,660
bytes that are contained in blocks and

125
00:06:27,008 --> 00:06:37,077
so each cache has there's s sets there's

126
00:06:32,939 --> 00:06:40,560
e e blocks per set and there's B bytes

127
00:06:37,077 --> 00:06:45,566
per block okay so the total cache size C

128
00:06:40,056 --> 00:06:47,435
is s times e times B okay now so there's

129
00:06:46,259 --> 00:06:50,330
a lot of terms to sort of keep straight

130
00:06:47,939 --> 00:06:53,011
and it's very easy to get to confuse the

131
00:06:50,969 --> 00:06:56,054
difference between lines and blocks and

132
00:06:53,659 --> 00:06:59,490
lines and sets okay so we'll go through

133
00:06:56,819 --> 00:07:02,888
some examples and hopefully these will

134
00:06:59,049 --> 00:07:08,052
start to make more sense now let's look

135
00:07:03,509 --> 00:07:12,515
at in general how we how the cache

136
00:07:08,052 --> 00:07:15,131
Hardware implements a read so when our

137
00:07:12,569 --> 00:07:17,644
program accesses when our program

138
00:07:15,599 --> 00:07:22,673
executes some instruction that

139
00:07:18,319 --> 00:07:26,384
references some word in memory the the

140
00:07:23,339 --> 00:07:30,300
CPU sends that address to the cache and

141
00:07:26,969 --> 00:07:32,026
s and it asked the cache to return the

142
00:07:30,003 --> 00:07:32,242
word

143
00:07:32,066 --> 00:07:41,134
the word at that address and so the cash

144
00:07:37,055 --> 00:07:46,064
takes that address this would be a

145
00:07:42,034 --> 00:07:50,102
64-bit address in case of x86 64 and if

146
00:07:47,045 --> 00:07:53,090
it divides the address into a number of

147
00:07:51,002 --> 00:07:55,070
of regions which are which are

148
00:07:53,009 --> 00:07:57,053
determined by the organization of the

149
00:07:55,007 --> 00:08:02,081
cache okay they're determined by those

150
00:07:58,034 --> 00:08:05,078
parameters s that's the s the number of

151
00:08:03,044 --> 00:08:08,141
steps a the number of lines per set and

152
00:08:05,078 --> 00:08:11,150
B the size of each data block so the low

153
00:08:09,041 --> 00:08:15,053
order bits there are B low order bits

154
00:08:12,005 --> 00:08:21,094
which determine the offset in the block

155
00:08:15,053 --> 00:08:26,071
that that word starts at the next s bits

156
00:08:22,039 --> 00:08:29,066
are treated as an unsigned integer which

157
00:08:26,071 --> 00:08:31,073
serves as an index into the array of

158
00:08:29,066 --> 00:08:32,162
Seth can remember we just think of these

159
00:08:31,091 --> 00:08:37,150
as think of this cache as an array of

160
00:08:33,062 --> 00:08:40,136
set the set index bits provide the index

161
00:08:38,005 --> 00:08:45,098
into the into this array of sets and

162
00:08:41,036 --> 00:08:49,118
then all of the remaining bits all of

163
00:08:46,043 --> 00:08:52,061
the remaining T bits constitute what we

164
00:08:50,018 --> 00:08:55,112
call a tag which will help us when we do

165
00:08:52,061 --> 00:08:59,129
our search so the cache logic takes this

166
00:08:56,012 --> 00:09:03,080
address and it first extracts the the

167
00:09:00,029 --> 00:09:06,047
set index and uses that to as an index

168
00:09:03,008 --> 00:09:09,056
into this array to identify the set that

169
00:09:06,047 --> 00:09:12,131
if this block is in the set I'm sorry if

170
00:09:10,028 --> 00:09:16,037
the data word if the block that contains

171
00:09:13,031 --> 00:09:20,035
the data word at this address is in the

172
00:09:17,018 --> 00:09:26,022
cache it's going to be in the set

173
00:09:20,071 --> 00:09:29,080
denoted by the the set index okay

174
00:09:26,022 --> 00:09:31,119
so first it identifies which index to

175
00:09:29,008 --> 00:09:31,047
look in

176
00:09:35,033 --> 00:09:43,058
and then it checks the tag it checks all

177
00:09:40,016 --> 00:09:45,020
of the lines in that set to see if

178
00:09:43,058 --> 00:09:47,147
there's any any of those lines have a

179
00:09:45,056 --> 00:09:51,122
matching tag that a tag that matches the

180
00:09:48,047 --> 00:09:55,070
the T the tag bits in the address okay

181
00:09:52,022 --> 00:09:56,641
and if any checks to see if the valid

182
00:09:55,007 --> 00:09:57,074
bit is turned on so if those two

183
00:09:56,839 --> 00:10:00,901
conditions hold if there's a line

184
00:09:58,037 --> 00:10:03,946
anywhere in the set as of where the

185
00:10:01,459 --> 00:10:07,910
valid bit is is one and there's a

186
00:10:04,279 --> 00:10:09,560
matching tag then we have a hit okay

187
00:10:07,091 --> 00:10:16,112
then the block that we're looking for is

188
00:10:09,056 --> 00:10:18,119
contained in this set okay if we once we

189
00:10:17,012 --> 00:10:21,080
determine that with that we've we've

190
00:10:19,019 --> 00:10:24,598
identified the block then the cash uses

191
00:10:21,008 --> 00:10:26,051
that the low-order B bits to determine

192
00:10:24,769 --> 00:10:29,720
where that where the data we're

193
00:10:27,023 --> 00:10:33,092
interested in begins okay within that

194
00:10:29,072 --> 00:10:36,121
block all right let's look at a more

195
00:10:33,092 --> 00:10:38,174
specific example for a the simplest kind

196
00:10:36,769 --> 00:10:43,795
of cash which is when e equals one when

197
00:10:39,074 --> 00:10:46,112
there's only one line per set okay so a

198
00:10:44,029 --> 00:10:52,370
equal one one line per set this kind of

199
00:10:47,012 --> 00:10:54,101
cash is called a direct mapped cache so

200
00:10:52,037 --> 00:10:57,496
here we have a sets each set consists of

201
00:10:55,001 --> 00:11:00,074
a single line and now the pro suppose

202
00:10:57,829 --> 00:11:04,690
our program references the data item at

203
00:11:00,074 --> 00:11:07,082
a particular address the CPU sense that

204
00:11:04,069 --> 00:11:08,164
address to the cache the cache takes

205
00:11:07,082 --> 00:11:13,094
that address breaks it up into these

206
00:11:09,064 --> 00:11:14,383
into these three fields and then for

207
00:11:13,094 --> 00:11:19,136
this particular address

208
00:11:14,959 --> 00:11:22,820
the block offset is four and the set

209
00:11:20,036 --> 00:11:24,625
index is one and then there's some tag

210
00:11:22,082 --> 00:11:26,110
bits which we'll just denote with with

211
00:11:24,949 --> 00:11:31,300
the color pink

212
00:11:27,001 --> 00:11:34,240
so the cache extracts the set index

213
00:11:31,003 --> 00:11:37,099
which is one and then it uses that as as

214
00:11:34,339 --> 00:11:38,260
the index into the set

215
00:11:40,839 --> 00:11:46,310
and then it can just it just ignores all

216
00:11:43,073 --> 00:11:48,107
the other de set de block we're looking

217
00:11:46,031 --> 00:11:51,092
for is is in the cash it's going to be

218
00:11:49,007 --> 00:11:54,011
in this inset number one then it does

219
00:11:51,092 --> 00:11:55,154
the comparison of the tag dips and the

220
00:11:54,011 --> 00:11:59,026
valid bits and assume that they assume

221
00:11:56,054 --> 00:12:01,079
that valid bits on and that it matches

222
00:11:59,026 --> 00:12:07,067
then it looks at the block offset which

223
00:12:01,079 --> 00:12:08,150
is four and which tells it that the the

224
00:12:07,067 --> 00:12:10,163
four by four by ten suppose that that's

225
00:12:09,005 --> 00:12:14,012
what the instruction was was referencing

226
00:12:11,063 --> 00:12:17,105
the four byte in begins that offset for

227
00:12:14,057 --> 00:12:20,102
so now the cache takes take this int and

228
00:12:18,005 --> 00:12:29,057
it sent it back to the to the CPU which

229
00:12:21,002 --> 00:12:34,025
puts it in the register okay if the tag

230
00:12:29,057 --> 00:12:35,446
doesn't match then the old-line if the

231
00:12:34,025 --> 00:12:39,101
tag doesn't match then there's a miss

232
00:12:35,959 --> 00:12:42,034
and in that case the cache has to fetch

233
00:12:40,001 --> 00:12:46,025
the the block the corresponding blocks

234
00:12:42,709 --> 00:12:49,760
from memory and then overwrite this

235
00:12:46,025 --> 00:12:51,068
block in the line and then it can serve

236
00:12:49,076 --> 00:12:53,174
then it can fetch it can get the word

237
00:12:51,068 --> 00:12:57,077
out of out of the block and send it back

238
00:12:54,074 --> 00:12:59,147
to the processor you know let me ask you

239
00:12:58,058 --> 00:13:01,085
a question just to see if kind of check

240
00:13:00,047 --> 00:13:05,075
to see if you're following along with

241
00:13:01,085 --> 00:13:08,143
this so if there's a Miss and the cache

242
00:13:05,075 --> 00:13:11,090
has to request the block from memory

243
00:13:09,043 --> 00:13:16,046
fetch it from memory and then overwrite

244
00:13:11,009 --> 00:13:20,036
the block in the current line does it

245
00:13:16,073 --> 00:13:22,151
also have to change the tag dips or two

246
00:13:21,017 --> 00:13:26,024
those stay the same so does the do the

247
00:13:23,051 --> 00:13:29,129
tag bits that were in this line get

248
00:13:26,087 --> 00:13:31,160
overwritten with a different value or is

249
00:13:30,029 --> 00:13:43,091
it the same

250
00:13:32,006 --> 00:13:45,100
same different save different now why

251
00:13:43,091 --> 00:13:45,154
would it be different

252
00:13:47,063 --> 00:13:56,962
we haven't changed yes I'm sorry

253
00:13:58,073 --> 00:14:03,075
Olek it almost certainly has different

254
00:14:01,949 --> 00:14:15,968
data but does it have a different

255
00:14:03,075 --> 00:14:18,093
address exactly it missed it missed

256
00:14:16,139 --> 00:14:21,500
because the tag it missed because the

257
00:14:18,093 --> 00:14:23,172
tag didn't match

258
00:14:21,005 --> 00:14:26,010
if the valid bit was false and the tag

259
00:14:24,072 --> 00:14:29,801
match then then that would also be a

260
00:14:26,055 --> 00:14:33,072
miss oh then you wouldn't okay that's

261
00:14:30,449 --> 00:14:41,910
right that's okay good good good okay

262
00:14:33,072 --> 00:14:44,076
great all right let me do a little let

263
00:14:41,091 --> 00:14:48,380
me do a really simple specific example

264
00:14:45,012 --> 00:14:52,068
of how a direct mapped cache works III

265
00:14:49,199 --> 00:14:54,240
want you to understand in real detail

266
00:14:52,068 --> 00:14:56,076
how this would work but I also want to

267
00:14:54,024 --> 00:15:00,053
make a point for about the weakness of

268
00:14:57,048 --> 00:15:01,277
direct mapped cache --is and why why you

269
00:15:00,269 --> 00:15:06,287
would want to have more than one line

270
00:15:01,709 --> 00:15:08,880
per set okay so we this is a really

271
00:15:06,449 --> 00:15:12,180
simple our met we have our memory system

272
00:15:08,088 --> 00:15:14,357
consists of 16 bytes okay so it's not a

273
00:15:12,018 --> 00:15:19,041
very useful system with 4-bit addresses

274
00:15:15,149 --> 00:15:24,050
and and it's broken up into blocks of 2

275
00:15:19,041 --> 00:15:27,047
bytes each our cache consists of 4 sets

276
00:15:24,005 --> 00:15:33,104
with one block per set

277
00:15:27,047 --> 00:15:36,416
now our 4 by our 4-bit addresses because

278
00:15:33,149 --> 00:15:39,180
be equal to that's 2 to the 1 we only

279
00:15:36,839 --> 00:15:42,720
need one block offset bit right there's

280
00:15:39,018 --> 00:15:44,237
only 2 bytes in a block so the byte

281
00:15:42,072 --> 00:15:48,156
we're looking for is either at 0 or 1

282
00:15:44,399 --> 00:15:52,920
okay because we have 4 sets we need to

283
00:15:49,056 --> 00:15:54,147
set off set index bits and then the

284
00:15:52,092 --> 00:15:57,881
remaining bits are always tag bits in

285
00:15:55,047 --> 00:15:59,088
this case there's just one tag dead all

286
00:15:58,709 --> 00:16:04,470
right now let's

287
00:15:59,088 --> 00:16:06,167
let's suppose that our program executes

288
00:16:04,047 --> 00:16:10,106
instructions that reference the

289
00:16:07,067 --> 00:16:13,143
following memory addresses zero one

290
00:16:10,529 --> 00:16:16,680
seven eight and zero and these

291
00:16:14,043 --> 00:16:18,051
references are reads that they're

292
00:16:16,068 --> 00:16:22,967
reading one byte per read okay like I

293
00:16:19,023 --> 00:16:25,052
said this is a really simple system so

294
00:16:23,579 --> 00:16:28,592
let's look at what happens now we start

295
00:16:25,259 --> 00:16:35,810
out Arte are initially are our cache is

296
00:16:28,709 --> 00:16:37,796
empty valid bits are all set to zero and

297
00:16:35,081 --> 00:16:42,123
now the cache receives the request for

298
00:16:38,579 --> 00:16:44,666
the byte that's at address zero so it

299
00:16:43,023 --> 00:16:49,050
extracts the set index bits which in

300
00:16:45,449 --> 00:16:54,630
this case are zero zero so these so it's

301
00:16:49,005 --> 00:16:55,104
going to look in set zero four and in

302
00:16:54,063 --> 00:17:00,066
this case since valid is zero it's just

303
00:16:56,049 --> 00:17:05,618
it's a Miss okay so it's etches that

304
00:17:00,066 --> 00:17:09,102
block from memory sticks the block so

305
00:17:06,059 --> 00:17:11,132
this memory this is the decent this is

306
00:17:10,002 --> 00:17:15,301
using array notation for memory so this

307
00:17:11,789 --> 00:17:18,150
is like the the byte that extend from

308
00:17:15,319 --> 00:17:24,750
offset zero to offset one inclusive in

309
00:17:18,015 --> 00:17:27,048
memory the tag bit is zero and the valid

310
00:17:24,075 --> 00:17:31,094
bit is 1 ok now the next the next

311
00:17:27,048 --> 00:17:34,059
address that comes by is for address 1

312
00:17:31,094 --> 00:17:37,107
well that's a hit right because we set

313
00:17:34,059 --> 00:17:40,094
block the block that contains the byte

314
00:17:38,007 --> 00:17:44,070
and address 1 is already in the cache

315
00:17:40,094 --> 00:17:46,188
the tag and the tags match okay so we're

316
00:17:44,007 --> 00:17:52,736
good that's a hit you now we get address

317
00:17:47,088 --> 00:17:55,092
7 so the cache extracts the set index

318
00:17:53,429 --> 00:18:01,830
bits which in this case are 1 1 or 4 or

319
00:17:56,028 --> 00:18:04,119
3 rather looks in set 3 there's no valid

320
00:18:01,083 --> 00:18:08,148
bit so that's a Miss and it loads the

321
00:18:05,019 --> 00:18:11,091
data for memory that spans

322
00:18:09,048 --> 00:18:15,103
bytes 6 & 7

323
00:18:11,091 --> 00:18:19,096
and in this case the the tag that is

324
00:18:16,003 --> 00:18:21,087
zero okay so we record that we record

325
00:18:19,096 --> 00:18:23,128
that in our metadata

326
00:18:21,087 --> 00:18:28,174
okay the next reference that comes by is

327
00:18:24,028 --> 00:18:34,062
8 now 8 has a set index of zero zero

328
00:18:29,074 --> 00:18:37,078
zero but that's currently occupied by

329
00:18:34,062 --> 00:18:42,070
block zero one and we can tell that

330
00:18:37,078 --> 00:18:45,082
because address 8 has a tag of 1 and the

331
00:18:42,007 --> 00:18:47,080
existing block of the block at the

332
00:18:45,082 --> 00:18:50,170
earlier address at address 0 has a tag

333
00:18:48,043 --> 00:18:55,120
of zero so that's a Miss so now we have

334
00:18:51,007 --> 00:18:58,074
to go fetch the block containing byte

335
00:18:56,002 --> 00:19:04,071
number 8 into memory so now we have

336
00:18:59,037 --> 00:19:09,121
bytes 8 & 9 and we in our new tag did

337
00:19:04,089 --> 00:19:14,107
okay now the next instruction is for

338
00:19:10,021 --> 00:19:16,030
byte 0 and we just we just replace we

339
00:19:15,007 --> 00:19:20,044
had that it we had that in our cache and

340
00:19:17,011 --> 00:19:24,025
we just replaced it so so it's another

341
00:19:20,044 --> 00:19:26,077
miss so that's unfortunate and it's the

342
00:19:24,025 --> 00:19:31,039
only reason we missed it is because

343
00:19:26,077 --> 00:19:37,135
we've got just one line per set and so

344
00:19:31,039 --> 00:19:40,101
we were forced to overwrite that that

345
00:19:38,035 --> 00:19:46,104
block containing bytes the block 0 1

346
00:19:41,001 --> 00:19:50,017
when we when we missed on on block 8 9

347
00:19:47,004 --> 00:19:51,070
okay so this and you see there's plenty

348
00:19:50,017 --> 00:19:54,115
of room in our cache we've still got

349
00:19:51,007 --> 00:19:57,034
we've got two two lines that we haven't

350
00:19:55,015 --> 00:20:01,039
even access right so we our cache is

351
00:19:57,097 --> 00:20:03,118
plenty big but just because of the sort

352
00:20:01,039 --> 00:20:06,130
of the low associativity of our cache

353
00:20:04,018 --> 00:20:08,067
and the sort of the pattern the access

354
00:20:07,003 --> 00:20:11,044
patterns that we were presented with

355
00:20:08,067 --> 00:20:16,068
we've got a miss that really was kind of

356
00:20:11,071 --> 00:20:15,168
unnecessary so oh yeah sorry

357
00:20:28,036 --> 00:20:35,119
six so when we referenced when we

358
00:20:32,179 --> 00:20:40,130
referenced a seven it's actually the

359
00:20:36,019 --> 00:20:42,508
it's at offset one in that block six

360
00:20:40,013 --> 00:20:44,075
seven okay since our blocks are two

361
00:20:42,679 --> 00:20:46,728
bytes they'll always start on an even

362
00:20:44,075 --> 00:20:46,494
multiple

363
00:20:51,021 --> 00:21:02,570
any other questions okay so this so this

364
00:21:00,059 --> 00:21:05,138
sort of is the reason why you have

365
00:21:02,759 --> 00:21:10,440
caches have higher associativity higher

366
00:21:05,849 --> 00:21:14,927
values of e so let's look at and so for

367
00:21:10,044 --> 00:21:19,973
for values of e greater for values of e

368
00:21:15,629 --> 00:21:21,647
greater than greater than one we refer

369
00:21:20,369 --> 00:21:25,382
to them as a way associate set

370
00:21:21,809 --> 00:21:28,876
associative caches so here e equals two

371
00:21:25,499 --> 00:21:32,552
so it's a 2-way it's 2-way associative

372
00:21:29,479 --> 00:21:36,479
so let's let's suppose we have a a 2-way

373
00:21:33,029 --> 00:21:39,035
a 2-way associative cache so here we

374
00:21:36,479 --> 00:21:42,536
have we have our array of sets and now

375
00:21:39,629 --> 00:21:48,650
each set contains two lines okay instead

376
00:21:43,049 --> 00:21:52,105
of one line and suppose we're presented

377
00:21:48,839 --> 00:21:54,866
with an address with the following form

378
00:21:52,609 --> 00:21:59,626
we're looking for the word that begins

379
00:21:55,109 --> 00:22:08,147
at an off set of four inside our block

380
00:21:59,779 --> 00:22:11,786
at within set number one okay so the

381
00:22:08,489 --> 00:22:17,542
cache extracts that set index so this is

382
00:22:12,479 --> 00:22:21,512
set 0 this is set 1 this is set to

383
00:22:18,019 --> 00:22:28,320
throws away all the other sets and now

384
00:22:21,809 --> 00:22:31,200
in parallel it searches it searches the

385
00:22:28,032 --> 00:22:34,591
tags it searches for a matching tag in

386
00:22:31,002 --> 00:22:37,211
both of these both of these lines and

387
00:22:34,879 --> 00:22:41,580
anti valid bits so if we get a matching

388
00:22:37,409 --> 00:22:47,491
tag and a valid bit true then we've got

389
00:22:41,058 --> 00:22:50,707
a a then we've got a hit now that yep

390
00:22:48,229 --> 00:22:51,229
yep

391
00:22:54,001 --> 00:23:00,079
oh it's a very good question so there's

392
00:22:58,045 --> 00:23:03,109
this hardware logic that does that

393
00:23:00,079 --> 00:23:05,167
compare and it's and that's the reason

394
00:23:04,009 --> 00:23:08,071
that as as the number of as the

395
00:23:06,067 --> 00:23:10,072
associativity goes up that logic gets

396
00:23:08,071 --> 00:23:13,075
more and more expensive okay it's like

397
00:23:11,017 --> 00:23:18,022
some like you're kind of doing some kind

398
00:23:13,075 --> 00:23:19,108
of tree search and so that actually is

399
00:23:18,022 --> 00:23:22,093
the limit that's why I mean because in

400
00:23:20,008 --> 00:23:27,045
general right that if you take this to

401
00:23:22,093 --> 00:23:29,101
the limit there's just one set with

402
00:23:27,045 --> 00:23:31,069
there's just it's we call that a fully

403
00:23:30,001 --> 00:23:35,002
associative cache so there's just one

404
00:23:31,069 --> 00:23:36,115
set and now any block a block can go

405
00:23:35,002 --> 00:23:39,094
anywhere right there's no constraints

406
00:23:37,015 --> 00:23:42,097
now where you place a block but the

407
00:23:39,094 --> 00:23:45,118
because of the complexity of that that

408
00:23:42,097 --> 00:23:49,138
fully associative search those are very

409
00:23:46,018 --> 00:23:52,027
rare in fact you do see will see fully

410
00:23:50,038 --> 00:23:55,129
associative caches caches but their

411
00:23:52,027 --> 00:24:00,069
software caches okay so in software and

412
00:23:56,029 --> 00:24:06,031
so the the complexity the hardware and

413
00:24:00,069 --> 00:24:07,156
sort of doesn't doesn't doesn't it's not

414
00:24:06,049 --> 00:24:10,075
worth it's not worth the complexity of

415
00:24:08,056 --> 00:24:12,127
the hardware for the penalty of having a

416
00:24:10,075 --> 00:24:14,122
lower associative 'ti okay but there are

417
00:24:13,027 --> 00:24:18,106
some systems later on when we study

418
00:24:15,022 --> 00:24:22,033
virtual memory the in a virtual memory

419
00:24:19,006 --> 00:24:25,039
system the DRAM serves as a cache for

420
00:24:22,033 --> 00:24:28,039
data stored on the disk and as we saw

421
00:24:25,039 --> 00:24:30,103
last time the penalty for a miss if you

422
00:24:28,093 --> 00:24:32,155
have a cache on DRAM and you miss and

423
00:24:31,003 --> 00:24:35,092
you have to go to disk the penalty is

424
00:24:33,055 --> 00:24:37,117
huge for that and so because of that

425
00:24:35,092 --> 00:24:41,164
it's worth it's worthwhile having very

426
00:24:38,017 --> 00:24:45,022
complex searches search algorithms in

427
00:24:42,064 --> 00:24:47,131
particular in a virtual memory system

428
00:24:45,067 --> 00:24:49,123
that the DRAM is implements a fully

429
00:24:48,031 --> 00:24:51,106
associative cache where blocks from disk

430
00:24:50,023 --> 00:24:54,067
can go anywhere we'll get into that

431
00:24:52,006 --> 00:24:55,099
later when we look in virtual memory but

432
00:24:54,067 --> 00:24:57,076
you're right you'll see in real systems

433
00:24:55,099 --> 00:24:59,196
nowadays that the number goes up right

434
00:24:58,057 --> 00:25:02,064
because feature sizes are going down and

435
00:25:00,096 --> 00:25:06,097
designers can afford to implement more

436
00:25:03,027 --> 00:25:07,066
expensive hardware but the the largest

437
00:25:06,097 --> 00:25:08,135
of

438
00:25:07,309 --> 00:25:12,830
tivity on Intel systems that I know of

439
00:25:09,035 --> 00:25:13,133
is 16-way associative l3 caches and then

440
00:25:12,083 --> 00:25:14,087
the others are 8 way associative so

441
00:25:14,033 --> 00:25:20,099
that's sort of the order of magnitude

442
00:25:15,023 --> 00:25:23,072
that's state of the art right now ok so

443
00:25:20,099 --> 00:25:26,038
then once we've identified a match we

444
00:25:23,072 --> 00:25:29,761
use the set offset bits in this case

445
00:25:26,929 --> 00:25:34,490
we're accessing a short int so 4 is the

446
00:25:30,409 --> 00:25:36,418
offset within the block of this the 2

447
00:25:34,049 --> 00:25:39,098
byte short int which then we can return

448
00:25:36,499 --> 00:25:41,690
to the processor alright so let's do

449
00:25:39,098 --> 00:25:44,647
that same simulation that we did before

450
00:25:41,069 --> 00:25:50,072
but this time with a 2-way associative

451
00:25:45,529 --> 00:25:52,555
cache now memory system is the same but

452
00:25:50,072 --> 00:25:56,144
now instead of one set we have two sets

453
00:25:52,789 --> 00:26:00,470
and I mean I'm sorry instead of four

454
00:25:57,044 --> 00:26:01,993
sets we have two sets so the cache this

455
00:26:00,047 --> 00:26:04,246
is the same sized cache but we're just

456
00:26:02,389 --> 00:26:06,391
going to organize it differently instead

457
00:26:04,669 --> 00:26:09,757
of one way instead of a direct mapped

458
00:26:06,409 --> 00:26:12,740
cache with four lines containing four

459
00:26:10,549 --> 00:26:14,620
lines one line per set we're going to

460
00:26:12,074 --> 00:26:16,169
implement a 2-way associative cache

461
00:26:15,259 --> 00:26:20,330
where we have two sets with two lines

462
00:26:17,069 --> 00:26:24,073
per set okay so each case is just four

463
00:26:20,033 --> 00:26:24,037
there's four total lines question

464
00:26:26,087 --> 00:26:32,129
and it was like oh so that that comes in

465
00:26:30,092 --> 00:26:35,185
with the request somehow and I actually

466
00:26:33,029 --> 00:26:39,046
don't know the details of that it may I

467
00:26:36,085 --> 00:26:40,163
guess there so it could ask for just

468
00:26:39,046 --> 00:26:45,095
there could just be a default sighs

469
00:26:41,063 --> 00:26:47,099
maybe it's always it's always a 64 by

470
00:26:45,095 --> 00:26:49,133
word and then the processor extracts

471
00:26:47,099 --> 00:26:52,103
that the current bits I actually don't

472
00:26:50,033 --> 00:26:54,119
know the details of that but it either

473
00:26:53,003 --> 00:26:56,099
comes in on the request or or there's a

474
00:26:55,019 --> 00:27:01,061
standard there's a standard size that

475
00:26:56,099 --> 00:27:02,141
the processor then parses out we'll just

476
00:27:01,061 --> 00:27:08,135
assume that the cache knows the wood

477
00:27:03,041 --> 00:27:10,049
size to return yes how do you decide

478
00:27:09,035 --> 00:27:12,038
which block to your place that's that's

479
00:27:11,021 --> 00:27:15,029
a really good question so there's a lot

480
00:27:12,065 --> 00:27:17,069
of different algorithms the most the

481
00:27:15,029 --> 00:27:20,114
most common algorithm or a common

482
00:27:17,069 --> 00:27:23,084
algorithm is least recently used so by

483
00:27:21,014 --> 00:27:25,016
locality you want to keep the you want

484
00:27:23,084 --> 00:27:27,167
to keep blocks in the cache that are

485
00:27:25,034 --> 00:27:30,053
being used a lot and so if a block isn't

486
00:27:28,067 --> 00:27:32,069
referenced for a long time by the

487
00:27:30,053 --> 00:27:35,132
principle of locality by sort of the

488
00:27:32,069 --> 00:27:37,163
inverse locality principle it's likely

489
00:27:36,032 --> 00:27:41,108
not to be addressed referenced in the

490
00:27:38,063 --> 00:27:44,102
near future so so that's one that's one

491
00:27:42,008 --> 00:27:47,069
algorithm that you just keep track of

492
00:27:45,002 --> 00:27:49,010
and and I'm not showing that there needs

493
00:27:47,069 --> 00:27:51,125
to be additional bits in the line to

494
00:27:49,082 --> 00:27:54,113
sort of keep like sort of virtual

495
00:27:52,025 --> 00:27:56,084
timestamps that but that's that's a

496
00:27:55,013 --> 00:27:59,075
that's sort of the general way you do it

497
00:27:56,084 --> 00:28:01,115
just try to keep the things that are the

498
00:27:59,075 --> 00:28:05,083
blocks that are being accessed the most

499
00:28:02,015 --> 00:28:06,019
frequently the most recently yes

500
00:28:08,001 --> 00:28:13,063
okay the question is what determines the

501
00:28:10,078 --> 00:28:15,130
block size that's determined by the

502
00:28:13,063 --> 00:28:18,148
design of the memory system so that's a

503
00:28:16,003 --> 00:28:21,052
that's that's a sixth parameter of the

504
00:28:19,048 --> 00:28:24,055
memory system so when the Intel

505
00:28:21,079 --> 00:28:27,088
designers decided to put cache memories

506
00:28:25,018 --> 00:28:36,072
on their processors they decided that

507
00:28:27,088 --> 00:28:35,172
the block size would be 64 bytes sorry

508
00:28:38,028 --> 00:28:46,066
so the block size comes the block size

509
00:28:42,064 --> 00:28:49,108
comes first then then you determine how

510
00:28:46,066 --> 00:28:52,149
big you want your cache to be okay and

511
00:28:50,008 --> 00:28:56,032
then and you determine the associativity

512
00:28:53,049 --> 00:28:57,124
okay and then once you determine the

513
00:28:56,032 --> 00:29:00,046
associativity and you know how big your

514
00:28:58,024 --> 00:29:01,099
cache is then that determines the number

515
00:29:00,046 --> 00:29:12,115
of sets okay

516
00:29:01,099 --> 00:29:14,173
so basically all of those the the the

517
00:29:13,015 --> 00:29:17,113
number of lines and the cat and the

518
00:29:15,073 --> 00:29:19,078
capacity the number of lines per set is

519
00:29:18,013 --> 00:29:22,069
sort of a sixth high level parameter

520
00:29:20,023 --> 00:29:25,117
design parameter the size of the cache

521
00:29:22,069 --> 00:29:27,121
is a is a high level design parameter

522
00:29:26,017 --> 00:29:32,025
and then the number of sets then is

523
00:29:28,021 --> 00:29:32,097
induced from from that okay yes

524
00:29:40,003 --> 00:29:46,004
that's that's yeah how does so that's

525
00:29:43,007 --> 00:29:47,015
that's the replacement policy how does

526
00:29:46,004 --> 00:29:48,098
it so question is how does it when

527
00:29:47,087 --> 00:29:50,132
there's multiple lines in a set how does

528
00:29:49,034 --> 00:29:53,042
it determine which to over-over right

529
00:29:51,032 --> 00:29:54,107
and that was what that was the previous

530
00:29:53,042 --> 00:29:57,068
question probably maybe I should have

531
00:29:55,007 --> 00:30:00,089
repeated it so you try to pick a line

532
00:29:57,068 --> 00:30:03,070
that that was least recently used so

533
00:30:00,089 --> 00:30:04,166
lines lines that haven't been accessed

534
00:30:03,007 --> 00:30:07,010
recently are good candidates for

535
00:30:05,066 --> 00:30:09,071
replacement because because of the sort

536
00:30:07,073 --> 00:30:11,078
of inverse locality principle right that

537
00:30:09,071 --> 00:30:13,088
they haven't been inversed referenced

538
00:30:12,023 --> 00:30:19,046
recently chances are they won't be

539
00:30:13,088 --> 00:30:19,175
referenced again it oh yeah there's

540
00:30:19,046 --> 00:30:23,054
additional bits that I'm not showing

541
00:30:20,075 --> 00:30:25,160
here that you have to so so when you

542
00:30:23,054 --> 00:30:28,061
replace a line in the set if that data

543
00:30:26,006 --> 00:30:30,068
has changed then it has to be written

544
00:30:28,061 --> 00:30:46,112
back to memory and that's another good I

545
00:30:31,022 --> 00:30:50,026
haven't shown yes ah so the so yeah so

546
00:30:47,012 --> 00:30:52,097
this is a really this is really tricky

547
00:30:50,062 --> 00:30:55,079
parameter right it's a it's a high level

548
00:30:52,097 --> 00:30:55,156
system parameter that's that it goes on

549
00:30:55,079 --> 00:30:58,157
for years

550
00:30:56,056 --> 00:31:02,117
so the idea you want to have blocks in

551
00:30:59,057 --> 00:31:03,140
order to exploit spatial locality right

552
00:31:03,017 --> 00:31:06,083
think about if you're going to go to the

553
00:31:04,004 --> 00:31:08,081
trouble of if you have a Miss in cache

554
00:31:06,083 --> 00:31:10,088
and you're going to go to the trouble of

555
00:31:09,017 --> 00:31:14,036
going all the way to memory to get some

556
00:31:11,033 --> 00:31:16,112
data you want to you want to amortize

557
00:31:14,036 --> 00:31:19,082
the cost of fetching that data by

558
00:31:17,012 --> 00:31:22,067
fetching more than one byte that's

559
00:31:19,082 --> 00:31:24,146
that's the motivation for blocks because

560
00:31:22,067 --> 00:31:30,083
by by the by the principle of locality

561
00:31:25,046 --> 00:31:32,051
in spatial locality in particular if you

562
00:31:30,083 --> 00:31:33,110
reference a word inside of a block

563
00:31:32,051 --> 00:31:35,093
chances are you're going to reference a

564
00:31:34,001 --> 00:31:36,050
nearby word which will also be an

565
00:31:35,093 --> 00:31:38,129
epilogue

566
00:31:36,059 --> 00:31:41,143
okay so blocks the whole purpose of

567
00:31:39,029 --> 00:31:46,638
blocks is to exploit spatial locality

568
00:31:42,043 --> 00:31:49,242
now if you make your block too small

569
00:31:46,899 --> 00:31:50,931
then you don't you don't amortize you

570
00:31:49,629 --> 00:31:53,666
don't get the same amortization right

571
00:31:51,219 --> 00:31:56,223
you maybe get one you bring the block in

572
00:31:53,999 --> 00:31:58,038
so there's a reference you get a mist

573
00:31:56,259 --> 00:31:59,346
you bring the block in there's another

574
00:31:58,389 --> 00:32:02,424
reference nearby you get a hit because

575
00:32:00,129 --> 00:32:04,167
the blocks are memory but then the next

576
00:32:02,739 --> 00:32:05,817
reference is in a different block

577
00:32:04,509 --> 00:32:09,546
because your block sizes are too small

578
00:32:06,519 --> 00:32:12,540
so you kind of want to make blocks big

579
00:32:09,879 --> 00:32:13,914
as big as possible but without slowing

580
00:32:12,729 --> 00:32:15,744
the system down so if you made your

581
00:32:14,229 --> 00:32:20,270
block size too big it would just take

582
00:32:15,879 --> 00:32:22,950
too long to bring that block in plus

583
00:32:20,639 --> 00:32:25,716
plus now your block that your blocks are

584
00:32:23,589 --> 00:32:27,621
taking up bits in your cache memory so

585
00:32:26,409 --> 00:32:29,442
now there's no room for other blocks

586
00:32:27,909 --> 00:32:32,931
right so it's a really it's a really

587
00:32:29,739 --> 00:32:34,776
tricky design problem right and I if

588
00:32:33,129 --> 00:32:36,580
we're doing it's taking an architecture

589
00:32:35,109 --> 00:32:39,111
class then we would we would sort of

590
00:32:36,058 --> 00:32:40,647
dive into the you know how how

591
00:32:39,309 --> 00:32:43,320
architects make those design decisions

592
00:32:41,169 --> 00:32:46,218
but in general that's what it's kind of

593
00:32:43,419 --> 00:32:49,451
a balancing act right there any other

594
00:32:46,659 --> 00:32:49,667
questions yes

595
00:32:52,088 --> 00:32:54,091
Oh

596
00:32:56,063 --> 00:32:59,096
the question is every time there's a

597
00:32:58,022 --> 00:33:02,026
myth do you have to do you have to

598
00:32:59,096 --> 00:33:04,132
select a victim line and overwrite it

599
00:33:02,062 --> 00:33:08,063
yeah I don't know of any caches that

600
00:33:05,032 --> 00:33:10,127
that don't do that now we'll see when we

601
00:33:08,063 --> 00:33:13,079
look at writes we'll see there's an

602
00:33:11,027 --> 00:33:15,092
option of whether we're only looking at

603
00:33:13,079 --> 00:33:18,173
reads right now but with writes that

604
00:33:15,092 --> 00:33:21,170
question does come up and if if you

605
00:33:19,073 --> 00:33:22,112
waited in a couple of slides we'll go

606
00:33:22,007 --> 00:33:26,014
over

607
00:33:23,012 --> 00:33:27,040
we'll go over that any other questions

608
00:33:28,018 --> 00:33:34,040
okay so let's look at this this two-way

609
00:33:31,001 --> 00:33:37,082
associative cache now there's there's

610
00:33:34,004 --> 00:33:39,050
one block offset bit we only have two

611
00:33:37,082 --> 00:33:41,123
sets so that we only need one set index

612
00:33:39,086 --> 00:33:44,153
and then the remaining two bits are

613
00:33:42,023 --> 00:33:48,089
tagged so let's go through our trace so

614
00:33:45,053 --> 00:33:52,139
address zero has a set is in set zero

615
00:33:48,089 --> 00:33:59,093
right here that's a Miss so we load that

616
00:33:53,039 --> 00:34:03,044
into memory with the reference to

617
00:34:00,029 --> 00:34:05,102
address one that's in set zero and

618
00:34:03,044 --> 00:34:09,056
that's a hit because that that byte is

619
00:34:06,002 --> 00:34:12,029
in is in our block the reference to

620
00:34:09,056 --> 00:34:13,103
seven is a Miss that's in set one so we

621
00:34:12,029 --> 00:34:16,091
load that and we were just picking

622
00:34:14,003 --> 00:34:20,056
randomly tick one of these two over

623
00:34:16,091 --> 00:34:22,118
right because they're the cache is empty

624
00:34:20,056 --> 00:34:25,139
the next reference is to address number

625
00:34:23,018 --> 00:34:28,070
eight which is in set zero now here's

626
00:34:26,039 --> 00:34:30,068
here's the difference between the direct

627
00:34:28,007 --> 00:34:32,015
mapped cache and this too late set

628
00:34:30,068 --> 00:34:37,076
associative cache when we when we

629
00:34:33,005 --> 00:34:39,098
reference address eight that block has

630
00:34:38,048 --> 00:34:43,145
to the corresponding block has to go

631
00:34:40,043 --> 00:34:46,046
into set 0 because of this 0 set index

632
00:34:44,045 --> 00:34:47,126
bit but we've got room now because we

633
00:34:46,073 --> 00:34:51,080
are set to have room for two lines

634
00:34:48,026 --> 00:34:54,092
instead of one so when we load that in

635
00:34:51,008 --> 00:34:55,055
well if we have an available empty slot

636
00:34:54,092 --> 00:34:57,113
we'll put it there we won't overwrite

637
00:34:56,027 --> 00:35:01,093
anything right so if possible always try

638
00:34:58,013 --> 00:35:04,062
to overwrite empty empty lines

639
00:35:01,093 --> 00:35:07,174
so now we've got in this set we've got

640
00:35:04,062 --> 00:35:11,118
block 0 1 and block 8 9 so when we get

641
00:35:08,074 --> 00:35:14,101
our reference to block to address 0

642
00:35:12,018 --> 00:35:16,054
whereas before with the when we had a

643
00:35:15,001 --> 00:35:19,030
conflict miss in the direct mapped cache

644
00:35:16,054 --> 00:35:21,073
now we can we can satisfy that that

645
00:35:19,003 --> 00:35:23,065
request it hits in memory and we can the

646
00:35:21,073 --> 00:35:28,147
cache can satisfy it from from the cache

647
00:35:23,092 --> 00:35:38,113
instead of going to memory ok so that

648
00:35:29,047 --> 00:35:40,113
makes sense ok now what about writes so

649
00:35:39,013 --> 00:35:43,108
there's multiple copies of the data

650
00:35:41,013 --> 00:35:46,081
right we're subsetting as we move up the

651
00:35:44,008 --> 00:35:52,075
hierarchy we're creating subsets of the

652
00:35:46,081 --> 00:35:57,088
data in the caches so what do we do if

653
00:35:52,075 --> 00:36:02,116
we do a write to a word within a block

654
00:35:58,051 --> 00:36:05,107
that's currently in the cache ok we have

655
00:36:03,016 --> 00:36:08,073
we have two options we can write that

656
00:36:06,007 --> 00:36:11,014
block immediately to memory right we're

657
00:36:08,073 --> 00:36:13,107
we've got a block that's like this big

658
00:36:11,014 --> 00:36:16,099
and we're updating a little chunk of it

659
00:36:14,007 --> 00:36:18,013
so we can we can either do the update

660
00:36:16,099 --> 00:36:20,182
and then flush it to memory immediately

661
00:36:18,067 --> 00:36:23,068
so that memory always mirrors the

662
00:36:21,082 --> 00:36:27,151
contents of memory always mirror the

663
00:36:23,068 --> 00:36:30,097
contents of the cache ok but that's

664
00:36:28,051 --> 00:36:33,139
expensive right I mean you know memory

665
00:36:30,097 --> 00:36:35,119
accesses are expensive the other so the

666
00:36:34,039 --> 00:36:36,082
other option is what what's called write

667
00:36:36,019 --> 00:36:39,058
back

668
00:36:36,082 --> 00:36:42,181
so in this case when we write to a block

669
00:36:39,058 --> 00:36:47,062
in the cache we don't we don't flush it

670
00:36:43,081 --> 00:36:49,105
to memory until we elect that particular

671
00:36:47,062 --> 00:36:53,095
line as a victim that's going to be

672
00:36:50,005 --> 00:36:56,026
overwritten and only then only then when

673
00:36:53,095 --> 00:36:57,123
we're just we sort of defer the writing

674
00:36:56,026 --> 00:37:01,120
to memory until the last possible minute

675
00:36:58,023 --> 00:37:05,038
we defer it until just before the cache

676
00:37:02,002 --> 00:37:07,033
would overwrite that that data block ok

677
00:37:05,038 --> 00:37:08,095
so that's called write back and for

678
00:37:07,051 --> 00:37:09,127
write back you need to have some an

679
00:37:08,095 --> 00:37:11,194
extra bit in the line that indicates

680
00:37:10,027 --> 00:37:15,088
whether that that blocks been written to

681
00:37:12,094 --> 00:37:16,192
so the algorithm is when when the cash

682
00:37:15,088 --> 00:37:20,113
identifies the particular line to

683
00:37:17,092 --> 00:37:22,099
overwrite it checks the dirty bit on

684
00:37:21,013 --> 00:37:29,014
that line if it's set then it writes

685
00:37:23,062 --> 00:37:30,085
that data to back to disk if the if the

686
00:37:29,014 --> 00:37:32,026
data hasn't if that block has a good

687
00:37:30,085 --> 00:37:33,130
written there's no point there's no need

688
00:37:32,026 --> 00:37:37,033
to write it back because it's the same

689
00:37:34,003 --> 00:37:42,091
it has the same value as the copy of the

690
00:37:37,033 --> 00:37:44,074
block on disk ok now so what about so

691
00:37:43,018 --> 00:37:46,099
that's a right here now what happens if

692
00:37:44,074 --> 00:37:50,083
we have a right missed so we're doing a

693
00:37:46,099 --> 00:37:53,176
right to memory and the word that we're

694
00:37:51,064 --> 00:37:57,130
writing is is not contained in any block

695
00:37:54,076 --> 00:37:59,080
that's in our cache so we have two

696
00:37:58,003 --> 00:38:01,042
options we can do what's called write

697
00:37:59,008 --> 00:38:03,013
allocate so we can treat it if if

698
00:38:01,069 --> 00:38:04,078
there's a Miss we can do sort of the

699
00:38:03,085 --> 00:38:07,150
symmetric thing that we did with it with

700
00:38:05,059 --> 00:38:10,072
the hit which was create a new a new

701
00:38:08,005 --> 00:38:14,050
line possibly overwriting an existing

702
00:38:10,072 --> 00:38:16,147
line and then write in so we could so we

703
00:38:14,095 --> 00:38:18,187
could create that cache enter that cache

704
00:38:17,047 --> 00:38:22,129
line fetch it from memory and then do

705
00:38:19,087 --> 00:38:24,109
and then do the do the right ok so this

706
00:38:23,029 --> 00:38:28,051
is sort of symmetric to reads right that

707
00:38:25,009 --> 00:38:31,036
so every right if it misses when the

708
00:38:28,051 --> 00:38:33,130
right finishes the that block will be in

709
00:38:31,036 --> 00:38:36,064
the cache and if we do a subsequent read

710
00:38:34,003 --> 00:38:40,006
we get a hit ok so that's that's the

711
00:38:36,064 --> 00:38:43,161
reason you might want to do that the

712
00:38:40,006 --> 00:38:46,012
other option is just to don't allocate a

713
00:38:44,061 --> 00:38:48,100
an entry in the cache don't allocate a

714
00:38:47,002 --> 00:38:52,090
new line just write write the data

715
00:38:49,000 --> 00:38:54,076
directly to memory you don't really need

716
00:38:53,008 --> 00:38:57,046
to understand the distinction between

717
00:38:54,076 --> 00:38:59,173
these two things different caches use

718
00:38:57,046 --> 00:39:03,118
different policies for your own mental

719
00:39:00,073 --> 00:39:06,124
model a good model to use is just to

720
00:39:04,018 --> 00:39:09,022
assume write back write allocate so just

721
00:39:07,024 --> 00:39:11,062
assume that we won't we won't copy the

722
00:39:09,022 --> 00:39:13,078
data to disk if there's a hit we won't

723
00:39:11,062 --> 00:39:16,105
write it back to disk until the last

724
00:39:13,078 --> 00:39:18,082
possible minute and every time there's a

725
00:39:17,005 --> 00:39:21,076
write miss we'll create a new entry in

726
00:39:19,018 --> 00:39:24,047
the cache ok so that's that I think

727
00:39:21,076 --> 00:39:25,103
that's sort of the simplest model that

728
00:39:24,047 --> 00:39:27,131
it's a reason it's a reasonable model

729
00:39:26,003 --> 00:39:33,098
that you can use regardless of the

730
00:39:28,031 --> 00:39:35,069
particular cache implementation now in a

731
00:39:33,098 --> 00:39:36,487
real system so far we've only looked at

732
00:39:35,069 --> 00:39:42,071
we've only assumed that there's a single

733
00:39:37,369 --> 00:39:48,200
cache but in real systems there's

734
00:39:42,089 --> 00:39:54,148
multiple multiple caches so modern core

735
00:39:48,002 --> 00:39:55,030
i7 Haswell architecture from intel

736
00:39:55,051 --> 00:40:00,143
contains multiple processor cores so 4

737
00:39:59,069 --> 00:40:04,076
is a typical number for like desktop

738
00:40:01,043 --> 00:40:06,131
systems 8 8 to 12 it's typical for

739
00:40:04,076 --> 00:40:08,104
server class systems these processor

740
00:40:07,031 --> 00:40:10,117
cores can each execute their own

741
00:40:09,004 --> 00:40:16,009
independent instruction stream in

742
00:40:11,017 --> 00:40:19,040
parallel and each processor core can

743
00:40:16,054 --> 00:40:22,061
contains general-purpose registers which

744
00:40:19,004 --> 00:40:27,005
that's level 0 in the cache and then 2

745
00:40:23,024 --> 00:40:31,025
different kinds of l1 caches the data

746
00:40:27,041 --> 00:40:33,139
cache the l1d cache and the eye cache

747
00:40:31,025 --> 00:40:37,121
the L which is the instruction cache and

748
00:40:34,039 --> 00:40:39,101
these are these are fairly small 32 K

749
00:40:38,021 --> 00:40:42,089
bytes they're eight-way associative and

750
00:40:40,001 --> 00:40:47,054
they can be accessed in a very small

751
00:40:42,089 --> 00:40:50,113
number of cycles the next level of the

752
00:40:47,054 --> 00:40:55,141
hierarchy is is the l is an l2 cache

753
00:40:51,013 --> 00:41:00,017
which is still fairly small 256 K bytes

754
00:40:56,041 --> 00:41:04,000
same associativity and it has a slightly

755
00:41:00,017 --> 00:41:06,026
longer access time and and it's unified

756
00:41:04,369 --> 00:41:11,570
in the sense that the l2 cache contains

757
00:41:07,007 --> 00:41:14,796
both data and instructions ok so that's

758
00:41:11,057 --> 00:41:17,132
all within a single core on the chip and

759
00:41:14,859 --> 00:41:20,180
then also on the chip but external to

760
00:41:18,032 --> 00:41:23,108
all the cores and shared by all the

761
00:41:20,018 --> 00:41:28,022
cores is at l3 unified cache which is 8

762
00:41:24,008 --> 00:41:32,082
megabytes and 16 Way associative with an

763
00:41:28,022 --> 00:41:37,053
access time that's like 40 to 75 cycles

764
00:41:32,082 --> 00:41:39,153
so if if there's a Miss in l1 then the

765
00:41:37,053 --> 00:41:42,066
l1 sensor tries to send a request to l2

766
00:41:40,053 --> 00:41:44,130
to try to try to find the data in l2

767
00:41:42,066 --> 00:41:46,113
since l2 is a little bigger maybe maybe

768
00:41:45,003 --> 00:41:50,016
the data hasn't been flushed out of l2

769
00:41:47,013 --> 00:41:53,058
yet if they'll - can't find it it sends

770
00:41:50,043 --> 00:41:56,049
a request to l3 to see if they can find

771
00:41:53,058 --> 00:41:58,071
the data in l3 if l3 can't find it then

772
00:41:57,003 --> 00:42:05,007
it gives up and it goes off chip to

773
00:41:58,071 --> 00:42:08,109
memory yes question yes name memories is

774
00:42:05,007 --> 00:42:11,091
that's it's the DRAM built of DRAM chips

775
00:42:09,009 --> 00:42:14,042
it's it's separate it's in a separate

776
00:42:11,091 --> 00:42:17,124
separate set of chips on the motherboard

777
00:42:14,042 --> 00:42:21,063
connected by those that i/o bridge that

778
00:42:18,024 --> 00:42:24,026
we and the bus various buses then that

779
00:42:21,063 --> 00:42:23,144
we talked about last time

780
00:42:28,048 --> 00:42:32,056
and for all different for all of these

781
00:42:31,027 --> 00:42:41,050
different caches the block size is 64

782
00:42:33,028 --> 00:42:43,081
bytes now there's a number of different

783
00:42:41,005 --> 00:42:49,030
ways to think about the performance of

784
00:42:43,081 --> 00:42:51,118
caches my most most common way is using

785
00:42:49,075 --> 00:42:53,116
a metric called the Miss rate so what

786
00:42:52,018 --> 00:42:58,096
this is the fraction of references that

787
00:42:54,016 --> 00:43:03,016
Miss so we're very so I thought and it's

788
00:42:58,096 --> 00:43:04,245
1 minus the hit rate so typical for

789
00:43:03,016 --> 00:43:08,092
caches to work then this rate has to be

790
00:43:05,109 --> 00:43:12,810
pretty low and and fortunately because

791
00:43:08,092 --> 00:43:15,139
of locality these Miss rates are low

792
00:43:12,081 --> 00:43:18,630
another another metric is the hit time

793
00:43:16,039 --> 00:43:21,091
so if if we do have a hit in the cache

794
00:43:19,359 --> 00:43:24,160
how long does it actually take to sort

795
00:43:21,091 --> 00:43:24,157
of look up the you know do the lookup to

796
00:43:24,016 --> 00:43:27,099
determine that there was a hit and then

797
00:43:25,057 --> 00:43:32,106
return the value okay

798
00:43:27,099 --> 00:43:34,117
so for for l1 and in a Intel system this

799
00:43:32,619 --> 00:43:37,716
is four clock cycles ten clock cycles

800
00:43:35,017 --> 00:43:41,020
for l2 and then there's an additional

801
00:43:38,589 --> 00:43:42,880
Costas so you always have to pay the hit

802
00:43:41,002 --> 00:43:47,005
time right the hit time is the best you

803
00:43:42,088 --> 00:43:50,113
can do but if you have a Miss then it's

804
00:43:47,023 --> 00:43:52,039
you pay the hit time because you have to

805
00:43:51,013 --> 00:43:53,089
do the search and eventually you're

806
00:43:52,039 --> 00:43:56,080
going to return the word back to the

807
00:43:53,089 --> 00:43:57,148
requester but you have this additional

808
00:43:56,008 --> 00:44:01,042
cost which you have to go which is going

809
00:43:58,048 --> 00:44:04,054
to the memory to fetch the data okay so

810
00:44:02,014 --> 00:44:07,102
that that missed penalty that's so

811
00:44:04,054 --> 00:44:10,833
called miss penalty is on the order of

812
00:44:08,002 --> 00:44:13,030
hundreds of cycles for main memory but

813
00:44:11,319 --> 00:44:15,327
in other levels of the hierarchy it can

814
00:44:13,003 --> 00:44:17,007
be huge so the miss penalty if you if

815
00:44:16,119 --> 00:44:20,121
you have a cache in main memory

816
00:44:17,007 --> 00:44:23,106
that's caching blocks that are stored on

817
00:44:20,319 --> 00:44:24,690
disk the the miss penalty is enormous

818
00:44:27,054 --> 00:44:34,057
so it's kind of interesting if you think

819
00:44:30,091 --> 00:44:35,119
about it that performance is the

820
00:44:34,084 --> 00:44:37,126
performance of these systems is very

821
00:44:36,019 --> 00:44:41,062
sensitive to the miss rate much more

822
00:44:38,026 --> 00:44:47,050
sensitive than you would think and in

823
00:44:41,062 --> 00:45:07,093
fact 99% hit rate is twice as good as a

824
00:44:47,005 --> 00:45:09,103
97% hit rate yes yeah they hit so the

825
00:45:07,093 --> 00:45:11,188
question is does the hit time include

826
00:45:10,048 --> 00:45:15,069
the time tax to access the tag and yes

827
00:45:12,088 --> 00:45:18,121
so the hit time is the time it takes to

828
00:45:15,069 --> 00:45:23,094
to search to determine if that item is

829
00:45:19,021 --> 00:45:23,094
is is in the cache and then return it

830
00:45:33,569 --> 00:45:42,250
so basically we'll use it a title

831
00:45:36,067 --> 00:45:44,226
property yeah so the yeah so the the

832
00:45:42,025 --> 00:45:47,026
Miss the Miss penalty is the time it

833
00:45:44,829 --> 00:45:49,900
takes for the cash to fetch the data

834
00:45:47,026 --> 00:45:52,048
from memory so that's all the latency

835
00:45:49,009 --> 00:45:53,478
you know going across the buses the time

836
00:45:52,048 --> 00:45:56,050
it takes the memory to respond to the

837
00:45:54,369 --> 00:45:59,230
requests the time he takes the data to

838
00:45:56,068 --> 00:46:01,947
flow back over the buses back to the the

839
00:45:59,023 --> 00:46:04,392
cache so the time for a Miss is going to

840
00:46:02,559 --> 00:46:08,190
be the hit time plus the Miss penalty

841
00:46:04,599 --> 00:46:08,190
that clear

842
00:46:08,076 --> 00:46:14,077
so I mean imagine suppose there's a hit

843
00:46:12,073 --> 00:46:15,130
time of one cycle and a Miss penalty of

844
00:46:14,077 --> 00:46:19,084
100 cycles that those are reasonable

845
00:46:16,003 --> 00:46:24,037
numbers so the average access access

846
00:46:20,047 --> 00:46:27,936
time if you have 97% hits it's the hit

847
00:46:24,064 --> 00:46:30,097
time plus the percentage of misses times

848
00:46:28,359 --> 00:46:33,490
the Miss penalty so that's four cycles

849
00:46:30,097 --> 00:46:34,153
for the average access time but if we

850
00:46:33,049 --> 00:46:39,618
just increase the the hit rate by two

851
00:46:35,053 --> 00:46:43,862
percent the average access time drops by

852
00:46:40,059 --> 00:46:44,087
50 percent a factor of two

853
00:46:46,018 --> 00:46:50,114
all right so why why is this stuff

854
00:46:49,061 --> 00:46:54,089
important why why should you care about

855
00:46:51,014 --> 00:46:56,063
it so cash is that we as we've seen are

856
00:46:54,089 --> 00:47:00,133
these they're automatic they're all

857
00:46:56,063 --> 00:47:03,109
built in hardware there's no part of the

858
00:47:01,033 --> 00:47:06,038
sort of the visible instruction set that

859
00:47:04,009 --> 00:47:11,015
lets you manipulate caches and you're

860
00:47:06,083 --> 00:47:12,169
somewhere between codons programs so

861
00:47:11,069 --> 00:47:18,080
that it all happens behind the scenes

862
00:47:13,069 --> 00:47:19,124
automatically in hardware but if you

863
00:47:18,008 --> 00:47:20,102
know how care if you know about the

864
00:47:20,024 --> 00:47:23,042
existence of caches and you have this

865
00:47:21,074 --> 00:47:25,097
general idea of how you can work how

866
00:47:23,042 --> 00:47:29,111
they work then you can write code that's

867
00:47:25,097 --> 00:47:32,138
cash friendly in the sense that your

868
00:47:30,011 --> 00:47:36,088
code will have a higher higher miss rate

869
00:47:33,038 --> 00:47:41,092
than code that that isn't cash friendly

870
00:47:36,088 --> 00:47:43,097
so the idea is to you want to focus on

871
00:47:41,092 --> 00:47:46,097
making the common case go fast don't

872
00:47:44,078 --> 00:47:48,106
spend your time on code that sort of

873
00:47:46,097 --> 00:47:51,098
code that doesn't get execute very much

874
00:47:49,006 --> 00:47:54,083
so look at look at the most commonly

875
00:47:51,098 --> 00:47:55,136
called functions and then within those

876
00:47:54,083 --> 00:47:56,144
functions look at the inner loop to

877
00:47:56,036 --> 00:47:59,132
those functions because it's the inner

878
00:47:57,044 --> 00:48:01,121
loops that are executing the most right

879
00:48:00,032 --> 00:48:04,070
so you can as a first approximation you

880
00:48:02,021 --> 00:48:06,023
can just ignore sort of stuff if you

881
00:48:04,007 --> 00:48:08,012
have nested loops you can ignore stuff

882
00:48:06,041 --> 00:48:10,138
that's going on in the outer loops and

883
00:48:08,075 --> 00:48:12,137
just focus on the code in the inner loop

884
00:48:11,038 --> 00:48:15,061
now what you want to do is try to

885
00:48:13,037 --> 00:48:18,095
minimize the misses in the inner loop

886
00:48:15,061 --> 00:48:21,079
okay so repeated references to a

887
00:48:18,095 --> 00:48:23,099
variable is variables are good

888
00:48:21,079 --> 00:48:25,112
especially if those are local variables

889
00:48:23,099 --> 00:48:28,148
right so remember if you declare a local

890
00:48:26,012 --> 00:48:32,015
variable and see the compiler can put

891
00:48:29,048 --> 00:48:34,100
that in a register right if you're

892
00:48:32,042 --> 00:48:36,053
referencing global variables maybe not

893
00:48:35,000 --> 00:48:39,056
the compiler doesn't know what's going

894
00:48:36,053 --> 00:48:41,105
on so it can't put that rough it can't

895
00:48:39,056 --> 00:48:45,074
put the reference to that variable in a

896
00:48:42,005 --> 00:48:48,038
C in a register okay so repeated

897
00:48:45,074 --> 00:48:50,093
references to local variables stored on

898
00:48:48,038 --> 00:48:52,109
the stack are good because those will

899
00:48:50,093 --> 00:48:55,151
get turned into register accesses you'll

900
00:48:53,009 --> 00:48:58,016
never go to memory okay also stride one

901
00:48:56,051 --> 00:49:00,056
accesses two arrays are good

902
00:48:58,079 --> 00:49:02,177
and they're good because of the

903
00:49:01,001 --> 00:49:05,048
existence of these blocks right so the

904
00:49:03,077 --> 00:49:06,115
only way you'd know that stride one

905
00:49:05,048 --> 00:49:11,090
references our good is if you knew that

906
00:49:07,015 --> 00:49:14,096
caches have the 64-byte blocks okay so

907
00:49:11,009 --> 00:49:16,016
they and strive one one reference will

908
00:49:14,096 --> 00:49:20,153
have half the Miss rate as a stride to

909
00:49:17,006 --> 00:49:24,008
reference because if you're doing stride

910
00:49:21,053 --> 00:49:27,092
one references the first reference to a

911
00:49:24,008 --> 00:49:31,019
word in a block will miss but then

912
00:49:27,092 --> 00:49:32,156
subsequent references will hit right and

913
00:49:31,091 --> 00:49:34,123
you'll hit if you're doing a stride one

914
00:49:33,056 --> 00:49:37,064
reference you're going to hit every

915
00:49:35,023 --> 00:49:39,101
every word in that block if your drive

916
00:49:38,036 --> 00:49:40,115
if you're doing stride two references

917
00:49:40,001 --> 00:49:43,094
you're only going to hit every other

918
00:49:41,015 --> 00:49:45,092
word right so you'll only get you get

919
00:49:43,094 --> 00:49:53,186
sort of half the so you'll missed at

920
00:49:45,092 --> 00:49:56,099
twice the rate so the basically the

921
00:49:54,086 --> 00:49:59,177
point I want to make you is that our

922
00:49:57,062 --> 00:50:03,101
understanding of caches allow us to sort

923
00:50:00,077 --> 00:50:04,163
of quantify this this qualitative notion

924
00:50:04,001 --> 00:50:07,100
of locality that we developed the last

925
00:50:05,063 --> 00:50:09,080
time right the last time we looked at we

926
00:50:08,000 --> 00:50:13,061
said if it's doing stride one references

927
00:50:09,008 --> 00:50:14,102
that's good if it's if we're doing if

928
00:50:13,061 --> 00:50:17,144
we're accessing the same variable over

929
00:50:15,074 --> 00:50:19,151
and over that's good but if we

930
00:50:18,044 --> 00:50:26,090
understand caches now we can quantify it

931
00:50:20,051 --> 00:50:28,082
in terms of miss rate all right so let's

932
00:50:26,009 --> 00:50:29,051
finish up the rest of the class we're

933
00:50:28,082 --> 00:50:33,110
going to look at the performance impact

934
00:50:30,032 --> 00:50:35,054
of caches on your code okay and why why

935
00:50:34,001 --> 00:50:38,012
you need why you need to know about

936
00:50:35,054 --> 00:50:41,120
these things and that the impact that

937
00:50:38,021 --> 00:50:45,056
they can have so there's a very

938
00:50:42,002 --> 00:50:47,027
interesting function that's actually

939
00:50:45,056 --> 00:50:49,150
plotted on the cover of your your text

940
00:50:47,045 --> 00:50:52,061
book that we call the memory Mountain I

941
00:50:50,005 --> 00:50:54,071
learned about this from a graduate

942
00:50:52,061 --> 00:50:57,116
student here at Carnegie Mellon back in

943
00:50:55,016 --> 00:51:01,052
the 90s so you develop this notion there

944
00:50:58,016 --> 00:51:05,030
Tom Stricker and what it is that say the

945
00:51:01,052 --> 00:51:07,124
memory Mountain plots a measure called

946
00:51:05,003 --> 00:51:09,065
read through put or read bandwidth which

947
00:51:08,024 --> 00:51:11,115
is the number of bytes read from memory

948
00:51:09,092 --> 00:51:14,501
so if you have four

949
00:51:12,015 --> 00:51:18,051
have a loop and you're scanning over a

950
00:51:15,329 --> 00:51:21,260
vector so you have a vector of say say

951
00:51:18,051 --> 00:51:22,880
double words and you're reading those

952
00:51:21,026 --> 00:51:25,089
elements from a vector one after the

953
00:51:23,339 --> 00:51:27,690
other the read throughput is the number

954
00:51:25,089 --> 00:51:29,123
of megabytes per second that you can

955
00:51:27,069 --> 00:51:33,072
that you can perform that task at and

956
00:51:30,023 --> 00:51:36,332
the memory mountian plots read

957
00:51:33,072 --> 00:51:40,119
throughput as a function of the temporal

958
00:51:36,539 --> 00:51:43,547
and spatial locality in that loop okay

959
00:51:41,019 --> 00:51:46,070
so in a sense it's looking at a wide

960
00:51:43,619 --> 00:51:48,900
range of locality options or

961
00:51:46,007 --> 00:51:50,126
characteristics in a program and it's

962
00:51:48,009 --> 00:51:53,061
plotting the performance of that memory

963
00:51:50,819 --> 00:51:56,400
system on that across that range is a

964
00:51:54,042 --> 00:51:58,125
two-dimensional function so in some ways

965
00:51:56,004 --> 00:52:00,060
the memory Mountain is a kind of a

966
00:51:59,025 --> 00:52:03,063
fingerprint right every system has its

967
00:52:00,096 --> 00:52:04,415
own unique memory Mountain that we can

968
00:52:03,063 --> 00:52:11,127
measure right by writing a simple

969
00:52:05,279 --> 00:52:15,450
program and so the idea here is that to

970
00:52:12,027 --> 00:52:18,286
construct the memory Mountain we write a

971
00:52:15,045 --> 00:52:18,124
program called test

972
00:52:35,019 --> 00:52:38,019
shoot

973
00:52:50,097 --> 00:53:02,103
for some reason it's not okay all right

974
00:53:03,259 --> 00:53:09,260
so we believe when we build a memory

975
00:53:05,819 --> 00:53:14,240
Mountain we're given a vector that

976
00:53:09,269 --> 00:53:14,240
consists of a collection of double words

977
00:53:14,093 --> 00:53:21,932
and then we write a loop that reads

978
00:53:20,049 --> 00:53:25,064
those words that read some number of

979
00:53:22,769 --> 00:53:25,640
words in this case

980
00:53:41,095 --> 00:53:49,504
there we go so it reads it reads Elam's

981
00:53:47,829 --> 00:53:52,460
number of elements right so we've got

982
00:53:50,359 --> 00:53:56,431
each of these double word elements with

983
00:53:52,046 --> 00:54:02,575
a stride of stride okay so if we have a

984
00:53:57,079 --> 00:54:05,098
stride of one I know those kind of

985
00:54:02,989 --> 00:54:10,940
redundant him so if we have a stride of

986
00:54:05,269 --> 00:54:12,324
one then we'll we'll have our loop

987
00:54:10,094 --> 00:54:14,473
wheels will sort of loop through and

988
00:54:12,819 --> 00:54:17,890
read these elements until we've read

989
00:54:15,319 --> 00:54:21,370
elements number of those elements okay

990
00:54:18,529 --> 00:54:24,410
and then we'll do it again and then that

991
00:54:21,829 --> 00:54:28,640
warms up the cache then we do it again

992
00:54:24,041 --> 00:54:30,067
and do exactly the same thing so if

993
00:54:28,064 --> 00:54:33,523
we're doing this with a stride of two

994
00:54:30,067 --> 00:54:42,145
then we will be reading we would read

995
00:54:34,099 --> 00:54:43,450
this word zero or LM - LM 4 and so on

996
00:54:44,559 --> 00:54:49,880
okay so well then what all we're doing

997
00:54:47,509 --> 00:54:54,650
we're just for wide range of strides and

998
00:54:49,088 --> 00:54:57,089
a wide range of sizes we're scanning

999
00:54:54,065 --> 00:55:00,065
over this vector and just recording how

1000
00:54:57,089 --> 00:55:02,096
long it takes to do that read and then

1001
00:55:00,065 --> 00:55:07,204
convert we convert that into megabytes

1002
00:55:02,096 --> 00:55:08,120
per second and in order to I just wanted

1003
00:55:07,789 --> 00:55:11,797
to show you this this is we don't need

1004
00:55:09,002 --> 00:55:14,551
we're not going to go into detail about

1005
00:55:11,869 --> 00:55:17,690
this but this is actually how I

1006
00:55:14,749 --> 00:55:20,758
generated the the cover on the book and

1007
00:55:17,069 --> 00:55:22,168
in order to in order to use to exploit

1008
00:55:20,839 --> 00:55:24,680
the parallelism inside the intel

1009
00:55:22,789 --> 00:55:26,420
processor like you learned about last

1010
00:55:24,068 --> 00:55:28,147
week there's there's a lot of parallel

1011
00:55:26,042 --> 00:55:33,721
functional units in order to exploit

1012
00:55:28,759 --> 00:55:36,170
those i i i did 4x4 loop unrolling so

1013
00:55:34,099 --> 00:55:39,920
I'm actually doing sort of four scans in

1014
00:55:36,017 --> 00:55:42,316
parallel but the general idea is just

1015
00:55:39,092 --> 00:55:45,451
what I've showed you here and this this

1016
00:55:42,469 --> 00:55:48,650
4x4 this 4x4 loop unrolling is just an

1017
00:55:46,279 --> 00:55:50,281
optimization but I wanted to show it to

1018
00:55:48,065 --> 00:55:50,117
you because it actually it's the exact

1019
00:55:50,479 --> 00:55:53,270
same

1020
00:55:51,017 --> 00:55:55,109
principles you learned about last week

1021
00:55:53,027 --> 00:56:00,044
when Professor Brian talked about code

1022
00:55:56,009 --> 00:56:02,053
optimization so what we do is we we call

1023
00:56:00,044 --> 00:56:06,044
this test function with these various

1024
00:56:02,053 --> 00:56:08,054
ranges of Elam's and stride and then we

1025
00:56:06,044 --> 00:56:10,082
measure the performance and we get this

1026
00:56:08,054 --> 00:56:12,056
beautiful picture this beautiful

1027
00:56:10,082 --> 00:56:22,124
function to me it's beautiful I don't

1028
00:56:12,074 --> 00:56:27,074
know is it look beautiful to you so on

1029
00:56:23,024 --> 00:56:29,063
the Z our z axis is plotting read

1030
00:56:27,074 --> 00:56:34,085
throughput in megabytes per second

1031
00:56:29,063 --> 00:56:42,071
ranging from 2000 megabytes per second

1032
00:56:34,085 --> 00:56:47,147
up to 16,000 megabytes per second this

1033
00:56:42,071 --> 00:56:51,080
this axis is measuring is stride

1034
00:56:48,047 --> 00:56:59,066
so going from stride 1 up to stride 12

1035
00:56:52,061 --> 00:57:02,099
and this axis is so as we as we increase

1036
00:56:59,066 --> 00:57:07,075
stride we're decreasing the spatial

1037
00:57:02,099 --> 00:57:06,175
locality all right

1038
00:57:08,269 --> 00:57:16,360
and this axis is the size axis so we're

1039
00:57:12,769 --> 00:57:18,844
going from I think 16 K up to 128

1040
00:57:17,179 --> 00:57:20,266
megabytes so this is the number of

1041
00:57:19,519 --> 00:57:28,527
elements we're going to read each pass

1042
00:57:21,049 --> 00:57:32,092
through so as we as we increase the size

1043
00:57:29,319 --> 00:57:36,385
we're sort of decreasing the impact of

1044
00:57:32,479 --> 00:57:38,494
temporal locality because work as we

1045
00:57:36,979 --> 00:57:40,063
increase the size there's fewer and

1046
00:57:38,629 --> 00:57:45,720
fewer caches in our hierarchy can hold

1047
00:57:40,819 --> 00:57:48,844
all that data and so this so we've got

1048
00:57:46,539 --> 00:57:50,607
spatial locality decreasing in this

1049
00:57:49,069 --> 00:57:54,148
direction and temporal locality

1050
00:57:51,219 --> 00:57:57,223
decreasing in this direction so as a

1051
00:57:54,859 --> 00:57:59,920
programmer what you want to do you want

1052
00:57:57,619 --> 00:58:02,662
to be up here right good spatial

1053
00:58:00,469 --> 00:58:05,476
locality good temporal locality because

1054
00:58:03,049 --> 00:58:09,100
you can get like 14 gigabytes per second

1055
00:58:06,169 --> 00:58:12,232
measure Greek throughput you don't want

1056
00:58:09,559 --> 00:58:13,630
to be down here which is only about 100

1057
00:58:12,799 --> 00:58:15,805
megabytes per second where you're

1058
00:58:14,269 --> 00:58:18,282
reading out of memory right so the

1059
00:58:16,399 --> 00:58:22,474
difference between reading all of your

1060
00:58:18,399 --> 00:58:26,401
data from memory and we or reading it

1061
00:58:23,149 --> 00:58:28,200
from some part of the the caches is huge

1062
00:58:26,599 --> 00:58:30,688
it's enormous

1063
00:58:28,659 --> 00:58:33,670
ok so because you're 213 students you'll

1064
00:58:31,489 --> 00:58:37,552
be up here and all the students that

1065
00:58:33,769 --> 00:58:39,817
didn't take 213 they'll be down here and

1066
00:58:38,119 --> 00:58:43,123
I've actually had I've actually had

1067
00:58:40,249 --> 00:58:44,344
people several people write back to tell

1068
00:58:43,519 --> 00:58:47,542
me about their experiences you know in

1069
00:58:45,199 --> 00:58:49,270
internships and jobs after they lost an

1070
00:58:47,749 --> 00:58:52,834
emu where they were given some code that

1071
00:58:49,909 --> 00:58:54,916
that was down here and they recognized

1072
00:58:53,599 --> 00:58:57,631
the locality issues and they got it

1073
00:58:55,609 --> 00:59:00,250
you know better up here or close at

1074
00:58:57,919 --> 00:59:04,480
least better

1075
00:59:00,025 --> 00:59:05,098
so this this picture this so-called

1076
00:59:04,048 --> 00:59:07,144
memory mountain has all kinds of

1077
00:59:05,098 --> 00:59:09,115
interesting features first of all

1078
00:59:08,044 --> 00:59:12,963
there's these what I call ridges of

1079
00:59:10,015 --> 00:59:14,074
temporal locality where these ridges see

1080
00:59:13,359 --> 00:59:16,210
these Ridge lines if you think of this

1081
00:59:14,074 --> 00:59:18,953
is like a mountain you see this

1082
00:59:16,021 --> 00:59:21,660
Ridgeline and you see this Ridgeline and

1083
00:59:19,619 --> 00:59:23,560
here's another ridge line and then

1084
00:59:21,849 --> 00:59:25,060
here's a here's another one these

1085
00:59:23,056 --> 00:59:26,140
correspond to different levels in the

1086
00:59:25,006 --> 00:59:29,022
hierarchy so this this top Ridgeline is

1087
00:59:27,004 --> 00:59:33,085
where you're reading directly out of l1

1088
00:59:29,022 --> 00:59:35,053
and it should be perfectly flat and it's

1089
00:59:34,021 --> 00:59:37,114
so fast that we're getting like

1090
00:59:35,053 --> 00:59:41,101
measurement jitter performance jitter

1091
00:59:38,014 --> 00:59:43,093
right but it's it's and this little

1092
00:59:42,001 --> 00:59:45,360
drop-off here is a measurement artifact

1093
00:59:43,093 --> 00:59:46,171
it it should it shouldn't be there

1094
00:59:45,369 --> 00:59:52,630
should be it should be flat and go all

1095
00:59:47,071 --> 00:59:55,980
the way to the wall back here and then

1096
00:59:52,063 --> 00:59:58,159
here this this ridge line is where we're

1097
00:59:56,619 --> 01:00:02,980
accessing l2 this is what we're

1098
00:59:59,059 --> 01:00:05,158
accessing l3 and and here's what we're

1099
01:00:02,098 --> 01:00:07,147
accessing mostly from memory so you have

1100
01:00:06,058 --> 01:00:10,093
these ridges of temporal locality and

1101
01:00:08,047 --> 01:00:13,072
then you have these slopes of decreasing

1102
01:00:10,093 --> 01:00:16,512
spatial locality so you see the slope

1103
01:00:13,072 --> 01:00:18,157
here as work so as we're moving from the

1104
01:00:17,349 --> 01:00:23,980
from the top of the slope down to the

1105
01:00:19,057 --> 01:00:25,093
bottom we're decreasing our spatial

1106
01:00:23,098 --> 01:00:27,130
locality so we're getting less benefit

1107
01:00:25,093 --> 01:00:30,124
for these blocks that we're bringing in

1108
01:00:28,003 --> 01:00:33,312
right so you can see the we're getting

1109
01:00:31,024 --> 01:00:35,092
less benefit out of the cost that we

1110
01:00:33,609 --> 01:00:40,210
went through of importing of fetching

1111
01:00:35,092 --> 01:00:43,521
these blocks and once the stride hits

1112
01:00:40,021 --> 01:00:46,024
the block size now every reference is

1113
01:00:44,349 --> 01:00:47,740
hitting a different block and so and

1114
01:00:46,024 --> 01:00:49,039
then it flattens out then you get you're

1115
01:00:47,074 --> 01:00:54,118
getting nose benefit from spatial

1116
01:00:49,039 --> 01:00:57,082
locality and similarly here is where

1117
01:00:55,018 --> 01:01:01,114
this this this slope is where we're

1118
01:00:57,082 --> 01:01:03,148
reading from l3 and and and it flattens

1119
01:01:02,014 --> 01:01:07,108
out always if they always flatten out at

1120
01:01:04,048 --> 01:01:09,177
the at the block size which is a stride

1121
01:01:08,008 --> 01:01:12,022
these are double words right so it's

1122
01:01:09,609 --> 01:01:15,160
stride of 8

1123
01:01:12,022 --> 01:01:17,074
is 64 bytes so once you exceed a stride

1124
01:01:15,016 --> 01:01:19,045
of eight then you're no longer you're

1125
01:01:17,074 --> 01:01:23,083
missing every time in it in a different

1126
01:01:19,045 --> 01:01:25,099
block and there's this interesting this

1127
01:01:24,064 --> 01:01:29,067
one puzzled me for a while

1128
01:01:25,099 --> 01:01:31,152
you might be wondering like how come

1129
01:01:29,067 --> 01:01:36,123
like over here as we increase the size

1130
01:01:32,052 --> 01:01:39,063
we can sort of we're sort of getting the

1131
01:01:37,023 --> 01:01:41,089
we're sort of as we increase the size

1132
01:01:39,063 --> 01:01:44,071
we're doing most of our references out

1133
01:01:41,089 --> 01:01:48,091
of caches that are lower in the cache

1134
01:01:44,071 --> 01:01:52,078
hierarchy but except when we're doing

1135
01:01:49,009 --> 01:01:56,083
stride one references you can see all

1136
01:01:53,041 --> 01:02:00,118
the way up to right at the end right

1137
01:01:56,083 --> 01:02:04,126
before it exceeds the size of l3 it's

1138
01:02:01,018 --> 01:02:07,102
flat okay

1139
01:02:05,026 --> 01:02:09,064
and it's it's running at the l2 rate and

1140
01:02:08,002 --> 01:02:11,053
so here's the l1 rate and then it drops

1141
01:02:09,064 --> 01:02:14,122
off and then it's running at a constant

1142
01:02:11,053 --> 01:02:18,085
l2 rate until the data no longer sits in

1143
01:02:15,022 --> 01:02:22,087
l3 so I think what's going on here is

1144
01:02:18,085 --> 01:02:26,146
that the hardware the cache the cache

1145
01:02:22,087 --> 01:02:28,174
the l2 cache hardware is recognizing or

1146
01:02:27,046 --> 01:02:31,075
maybe it's an l1 but some some some

1147
01:02:29,074 --> 01:02:32,155
logic in that in the cache system is

1148
01:02:31,075 --> 01:02:35,161
recognizing the stride one reference

1149
01:02:33,055 --> 01:02:38,137
pattern because it sees all the

1150
01:02:36,061 --> 01:02:41,080
addresses it's wrecked it's recognizing

1151
01:02:39,037 --> 01:02:45,042
that stride one pattern and then it's

1152
01:02:41,008 --> 01:02:48,094
aggressively prefetching from l3 into l2

1153
01:02:45,087 --> 01:02:50,143
so that those so it's such an ahead of

1154
01:02:49,066 --> 01:02:53,083
time it's anticipating it saying look

1155
01:02:51,043 --> 01:02:55,090
I've gotten five stride one references

1156
01:02:53,083 --> 01:02:56,179
in a row I'm going to go grab a whole

1157
01:02:55,009 --> 01:02:59,032
bunch of blocks and load them all up

1158
01:02:57,079 --> 01:03:03,100
because by the principle of spatial

1159
01:03:00,013 --> 01:03:04,096
locality those blocks those blocks are

1160
01:03:04,000 --> 01:03:07,099
going to be referenced in the near

1161
01:03:04,096 --> 01:03:08,122
future so this was really neat and this

1162
01:03:07,099 --> 01:03:10,126
only happened within the last couple

1163
01:03:09,022 --> 01:03:16,063
years so the Intel engineers are always

1164
01:03:11,026 --> 01:03:19,051
hard at work and maybe by the time the

1165
01:03:16,063 --> 01:03:22,069
time we do the next the next edition of

1166
01:03:19,051 --> 01:03:24,094
the memory mountain those systems will

1167
01:03:22,069 --> 01:03:27,145
recognize stride 2 and you know other

1168
01:03:24,094 --> 01:03:29,119
stride patterns too but from this data

1169
01:03:28,045 --> 01:03:32,073
it appears that it's only recognizing

1170
01:03:30,019 --> 01:03:32,073
stride 1

1171
01:03:35,032 --> 01:03:43,064
okay so you can real we can improve the

1172
01:03:41,096 --> 01:03:46,108
spatial and temporal locality of our

1173
01:03:43,064 --> 01:03:49,088
programs in several different ways that

1174
01:03:47,008 --> 01:03:52,016
one way to improve the spatial locality

1175
01:03:49,088 --> 01:03:55,139
is to rearrange loops and I'll use

1176
01:03:52,088 --> 01:03:58,187
matrix multiplication as an example so

1177
01:03:56,039 --> 01:04:03,074
here's a sort of a simple matrix

1178
01:03:59,087 --> 01:04:06,176
multiplication in code where we're

1179
01:04:03,074 --> 01:04:11,108
multiplying a times B and adding it

1180
01:04:07,076 --> 01:04:16,154
we're taking what's in of the IJ element

1181
01:04:12,008 --> 01:04:20,102
of C and then to that we're adding the

1182
01:04:17,054 --> 01:04:25,133
sum the inner product of row I of a and

1183
01:04:21,002 --> 01:04:28,058
the row J a column J of B okay and then

1184
01:04:26,033 --> 01:04:31,094
so we're going through and for each IJ

1185
01:04:28,058 --> 01:04:36,115
in this matrix C we're computing an

1186
01:04:31,094 --> 01:04:39,101
inner product and then creating that sum

1187
01:04:37,015 --> 01:04:41,021
so we can actually turns out there's a

1188
01:04:40,064 --> 01:04:44,081
lot of different ways to do matrix

1189
01:04:41,075 --> 01:04:47,171
multiply and this is we can permute

1190
01:04:44,081 --> 01:04:50,159
these these loops in any of six

1191
01:04:48,071 --> 01:04:53,156
different possible permutations so this

1192
01:04:51,059 --> 01:04:56,060
is a permutation where it's I followed

1193
01:04:54,056 --> 01:05:01,133
by J followed by K but five other

1194
01:04:56,069 --> 01:05:03,146
possibilities are feasible and so we can

1195
01:05:02,033 --> 01:05:06,095
actually analyze those those different

1196
01:05:04,046 --> 01:05:09,137
permutations and predict which one will

1197
01:05:06,095 --> 01:05:10,103
have the best performance okay so what

1198
01:05:10,037 --> 01:05:16,043
we'll do is we'll look at the inner loop

1199
01:05:11,075 --> 01:05:18,110
and we'll look at the access pattern of

1200
01:05:16,097 --> 01:05:22,180
the inner loops and since the access

1201
01:05:19,001 --> 01:05:23,008
pattern on arrays C a and D

1202
01:05:24,062 --> 01:05:30,155
okay so let's look at the ijk

1203
01:05:29,003 --> 01:05:34,069
implementation that I just showed you so

1204
01:05:31,055 --> 01:05:38,060
as always we focus on the inner loop and

1205
01:05:34,069 --> 01:05:42,128
if you notice this inner loop is doing a

1206
01:05:39,005 --> 01:05:45,098
row wise access of column a and a column

1207
01:05:43,028 --> 01:05:49,091
wise access I'm sorry a row wise access

1208
01:05:45,098 --> 01:05:53,177
of array a and column wise access of a

1209
01:05:49,091 --> 01:05:55,163
row B so row wise of a column wise of B

1210
01:05:54,077 --> 01:05:57,161
we don't really care about C because

1211
01:05:56,063 --> 01:06:03,071
it's out it's not in the inner loop okay

1212
01:05:58,061 --> 01:06:05,137
so just ignore that so given our

1213
01:06:04,043 --> 01:06:09,050
assumption that we can hold in this case

1214
01:06:06,037 --> 01:06:12,101
we're assuming that we can hold for four

1215
01:06:10,013 --> 01:06:16,088
of these integer elements in a in one

1216
01:06:13,001 --> 01:06:18,008
block so the row wise access which has

1217
01:06:16,088 --> 01:06:20,159
good spatial locality will miss one

1218
01:06:18,071 --> 01:06:22,169
every four accesses okay the very first

1219
01:06:21,059 --> 01:06:25,061
reference will miss and then the next

1220
01:06:23,069 --> 01:06:26,108
three will hit and then the next

1221
01:06:25,079 --> 01:06:29,173
reference after that will hit a new

1222
01:06:27,008 --> 01:06:34,010
block okay so so one out of four

1223
01:06:30,073 --> 01:06:35,147
references to a will miss but because

1224
01:06:34,001 --> 01:06:40,049
the access pattern for B is column wise

1225
01:06:36,047 --> 01:06:42,116
every every every reference to B will

1226
01:06:40,058 --> 01:06:44,099
miss okay so the average number of

1227
01:06:43,016 --> 01:06:49,019
misses per loop iteration is one point

1228
01:06:44,099 --> 01:06:51,154
two five okay the j iik version is

1229
01:06:49,019 --> 01:06:52,054
exactly the same pattern

1230
01:06:54,051 --> 01:07:02,124
kij is a little different here we're

1231
01:06:59,004 --> 01:07:05,082
doing row-wise access of b and a row

1232
01:07:03,024 --> 01:07:07,643
wise access of c so that's good right so

1233
01:07:05,082 --> 01:07:10,086
now we've got stride one accesses on

1234
01:07:07,859 --> 01:07:12,860
both BMC and the reference to a is

1235
01:07:11,022 --> 01:07:17,040
outside of the loop so we don't care

1236
01:07:12,869 --> 01:07:20,550
about it so so both B and C will miss

1237
01:07:17,004 --> 01:07:22,005
one quarter of the time okay so the

1238
01:07:20,055 --> 01:07:25,089
total average number of misses per loop

1239
01:07:22,005 --> 01:07:29,030
iteration will be 0.5 that's pretty good

1240
01:07:25,089 --> 01:07:31,188
and I KJ has the same similar behavior

1241
01:07:29,075 --> 01:07:36,164
now jki is sort of the exact opposite

1242
01:07:32,088 --> 01:07:39,177
jki does column-wise access of a and

1243
01:07:37,064 --> 01:07:41,064
column wise access of c so right we know

1244
01:07:40,077 --> 01:07:45,123
that's a stinker

1245
01:07:41,064 --> 01:07:48,075
right and and we qualitatively know it's

1246
01:07:46,023 --> 01:07:52,044
bad and we can compute that it will miss

1247
01:07:48,075 --> 01:07:53,684
a one time per loop iteration so that

1248
01:07:52,044 --> 01:07:56,082
will be two total of two misses per

1249
01:07:54,359 --> 01:07:59,730
iteration and kji has the same bad

1250
01:07:56,082 --> 01:08:03,126
pattern okay so if we look at all these

1251
01:07:59,073 --> 01:08:10,080
permutations you can see that ijk and ji

1252
01:08:04,026 --> 01:08:14,085
k miss 1.25 has 1.25 mrs. K IJ has 0.5

1253
01:08:10,008 --> 01:08:17,016
misses and j ki has two misses so

1254
01:08:14,085 --> 01:08:19,994
clearly it looks like ki J and its

1255
01:08:17,088 --> 01:08:23,127
brethren are the best option the only

1256
01:08:20,759 --> 01:08:25,760
difference is that K ki J has this

1257
01:08:24,027 --> 01:08:27,093
additional store so there might be a

1258
01:08:25,859 --> 01:08:29,957
question that is that going to create is

1259
01:08:27,093 --> 01:08:34,098
that going to slow things down well it

1260
01:08:30,839 --> 01:08:38,040
turns out in systems and any kind

1261
01:08:34,098 --> 01:08:40,122
storage systems rights are much easier

1262
01:08:38,004 --> 01:08:44,016
to deal with them reads can it can you

1263
01:08:41,022 --> 01:08:45,027
think about why that might be true so

1264
01:08:44,016 --> 01:08:48,020
right you have a lot more flexibility

1265
01:08:45,072 --> 01:08:47,156
than you do with Ruiz

1266
01:08:49,779 --> 01:08:55,500
I mean yes

1267
01:08:56,179 --> 01:09:01,500
that's exactly so you can have options

1268
01:08:59,759 --> 01:09:04,772
you can do you can write back defer you

1269
01:09:01,005 --> 01:09:06,164
can defer writing until the value the

1270
01:09:04,889 --> 01:09:08,900
value that your written is actually used

1271
01:09:06,659 --> 01:09:10,748
but when you read an item you're stuck

1272
01:09:08,009 --> 01:09:12,908
you can't do anything until until you

1273
01:09:11,549 --> 01:09:15,750
get that data so it turns out that that

1274
01:09:13,799 --> 01:09:17,897
rights don't really that this additional

1275
01:09:15,075 --> 01:09:21,150
store doesn't really hurt us and so when

1276
01:09:18,779 --> 01:09:27,150
we measure these on a modern system you

1277
01:09:22,005 --> 01:09:30,224
can see that the the Kate kij which has

1278
01:09:27,015 --> 01:09:33,524
the the fewest number of misses has you

1279
01:09:30,719 --> 01:09:35,400
see we're getting like one miss Oh what

1280
01:09:33,659 --> 01:09:38,040
we're plotting here is cycles per inner

1281
01:09:35,004 --> 01:09:39,473
loop iteration so each each iteration is

1282
01:09:38,004 --> 01:09:44,025
taking about one cycle which is really

1283
01:09:39,869 --> 01:09:46,904
good this i JK pattern which is kind of

1284
01:09:44,025 --> 01:09:49,124
the intermediate 1.2 misses that's sort

1285
01:09:47,219 --> 01:09:52,271
of in between and the JK I which has two

1286
01:09:49,349 --> 01:09:53,423
misses per iteration is the worst ok so

1287
01:09:52,739 --> 01:09:56,752
what's interesting is we could actually

1288
01:09:54,089 --> 01:09:58,770
just by doing a little bit of analysis

1289
01:09:56,869 --> 01:10:01,320
simple analysis we could actually

1290
01:09:58,077 --> 01:10:06,105
predict what this what this graph would

1291
01:10:01,032 --> 01:10:08,076
look like ok in the in left last 10

1292
01:10:07,005 --> 01:10:10,082
minutes of the class we're going to look

1293
01:10:08,076 --> 01:10:12,084
at how to improve temporal locality now

1294
01:10:10,082 --> 01:10:14,163
so what we did with with when we

1295
01:10:13,056 --> 01:10:16,127
rearranged our loops in the matrix

1296
01:10:15,063 --> 01:10:21,078
multiplication what we were doing was in

1297
01:10:17,027 --> 01:10:22,706
improving our spatial locality right but

1298
01:10:21,078 --> 01:10:24,707
we didn't we didn't really do anything

1299
01:10:22,949 --> 01:10:25,958
to improve the temporal locality to

1300
01:10:25,409 --> 01:10:29,760
improve temporal locality you have to

1301
01:10:26,849 --> 01:10:31,560
use a technique called blocking and this

1302
01:10:29,076 --> 01:10:31,161
is important to understand because

1303
01:10:31,056 --> 01:10:35,061
you're going to need it in your cache

1304
01:10:32,061 --> 01:10:37,155
lab for one thing but it's also a very

1305
01:10:35,061 --> 01:10:39,440
general technique anytime you need any

1306
01:10:38,055 --> 01:10:45,138
time you're having issues with temporal

1307
01:10:39,989 --> 01:10:48,008
locality okay so we're not going to go

1308
01:10:46,038 --> 01:10:52,607
into too much detail this code but what

1309
01:10:48,179 --> 01:10:54,000
I did I rewrote the matrix multiply so

1310
01:10:52,949 --> 01:10:55,590
that it operates you know a

1311
01:10:54,000 --> 01:10:56,849
two-dimensional matrix that you can

1312
01:10:55,059 --> 01:10:58,125
really just think of it as a contiguous

1313
01:10:56,849 --> 01:11:01,380
array of bytes so I just rewrote this

1314
01:10:59,025 --> 01:11:03,090
code to operate on a contiguous array

1315
01:11:01,038 --> 01:11:06,063
one-dimensional array and then I'm doing

1316
01:11:03,009 --> 01:11:08,070
the indexing explicitly here so here at

1317
01:11:06,063 --> 01:11:10,155
CI x then plus J

1318
01:11:09,051 --> 01:11:14,330
this is an n-by-n matrix what I'm doing

1319
01:11:11,055 --> 01:11:16,119
is I'm I'm accessing the I'm computing

1320
01:11:14,789 --> 01:11:18,866
where the I throw starts and then I'm

1321
01:11:17,019 --> 01:11:27,428
going to the J column of that row and

1322
01:11:19,559 --> 01:11:29,590
then accessing that element all right so

1323
01:11:27,599 --> 01:11:32,605
let's but it's the same idea as before

1324
01:11:29,869 --> 01:11:34,925
so let's look at the Miss rate for this

1325
01:11:32,659 --> 01:11:38,705
this is just our original this is our

1326
01:11:35,429 --> 01:11:41,340
original unblocked matrix multiply so

1327
01:11:39,119 --> 01:11:46,136
what we're doing is we're we're

1328
01:11:41,034 --> 01:11:48,075
computing C 0 0 and we're doing that by

1329
01:11:46,289 --> 01:11:54,382
taking an inner product of row 0 and

1330
01:11:48,075 --> 01:11:57,194
column 0 oops so if you look at the

1331
01:11:55,219 --> 01:11:59,228
we're assuming that the cache the cache

1332
01:11:57,869 --> 01:12:02,730
blocks holds eight doubles and that the

1333
01:12:00,119 --> 01:12:04,198
matrix elements are doubles then we're

1334
01:12:02,073 --> 01:12:10,128
going to miss one eighth of the time

1335
01:12:04,909 --> 01:12:14,760
okay so in the first iteration we're

1336
01:12:11,028 --> 01:12:15,617
going to miss the first iteration does

1337
01:12:14,076 --> 01:12:17,142
any of these things

1338
01:12:15,869 --> 01:12:22,980
and since we're missing n over eight at

1339
01:12:18,042 --> 01:12:27,761
the time what we're missing one block

1340
01:12:22,098 --> 01:12:29,927
for every eight eight references for

1341
01:12:28,139 --> 01:12:34,187
each for the first iteration we're going

1342
01:12:30,809 --> 01:12:35,900
to miss n over eight and since there's n

1343
01:12:34,619 --> 01:12:42,420
for each element for each block I'm

1344
01:12:36,719 --> 01:12:43,724
sorry and then oh so this is the number

1345
01:12:42,042 --> 01:12:45,111
of blocks and the number of misses and

1346
01:12:44,219 --> 01:12:49,219
then we have n elements so that the

1347
01:12:46,011 --> 01:12:51,048
total number of misses is nine over n

1348
01:12:49,219 --> 01:12:56,219
divided by eight misses for the first

1349
01:12:51,048 --> 01:12:58,187
iteration okay the second iteration will

1350
01:12:56,219 --> 01:13:00,960
have the same number of misses because

1351
01:12:58,619 --> 01:13:03,704
of our assumptions about the the size of

1352
01:13:00,096 --> 01:13:05,465
this array so this these rows are way

1353
01:13:04,469 --> 01:13:08,480
too big to fit in the cache so we never

1354
01:13:06,329 --> 01:13:11,420
get any we don't get any temporal

1355
01:13:08,579 --> 01:13:14,666
locality okay so the total number of

1356
01:13:12,239 --> 01:13:17,010
misses is nine n over eight times the

1357
01:13:15,449 --> 01:13:18,533
number of elements that we're updating

1358
01:13:17,001 --> 01:13:22,001
which is N squared okay so our total

1359
01:13:19,289 --> 01:13:26,480
misses is nine over eight times and

1360
01:13:22,001 --> 01:13:30,008
and in cubed now let's rewrite the code

1361
01:13:26,048 --> 01:13:32,126
to use blocking and so you can look at

1362
01:13:30,071 --> 01:13:35,120
this code later but it's much simpler

1363
01:13:33,026 --> 01:13:39,068
just to just to look at it pictorially

1364
01:13:36,002 --> 01:13:42,101
so what what we're doing instead of

1365
01:13:39,068 --> 01:13:47,077
updating one element at a time we're

1366
01:13:43,019 --> 01:13:50,096
updating a sub block a B by B sub block

1367
01:13:47,077 --> 01:13:52,175
and we're doing that just totally

1368
01:13:50,096 --> 01:13:57,098
analogously to when our original case

1369
01:13:53,075 --> 01:14:00,107
where B equal one this this B by B sub

1370
01:13:58,016 --> 01:14:05,845
block in C is computed by taking an

1371
01:14:01,007 --> 01:14:10,028
inner product of the sub blocks of a set

1372
01:14:05,989 --> 01:14:12,950
of sub blocks in a with a set of sub

1373
01:14:10,028 --> 01:14:14,042
blocks in B and for each one of those

1374
01:14:12,095 --> 01:14:16,130
we're doing a little mini matrix

1375
01:14:14,042 --> 01:14:20,075
multiplication so we're taking we're

1376
01:14:17,003 --> 01:14:24,050
taking this sub block times this sub

1377
01:14:20,075 --> 01:14:28,114
block plus the second sub block of a

1378
01:14:24,077 --> 01:14:31,085
times the second sub block of of B plus

1379
01:14:29,014 --> 01:14:35,027
the third sub block of a times the third

1380
01:14:32,057 --> 01:14:36,119
sub block of B and so on okay so we're

1381
01:14:35,027 --> 01:14:39,029
doing the same inner product operation

1382
01:14:37,019 --> 01:14:41,036
but instead of scalars we're doing it

1383
01:14:39,029 --> 01:14:46,117
with these little sub these little tiny

1384
01:14:41,036 --> 01:14:49,058
matrices okay all right so let's look at

1385
01:14:47,017 --> 01:14:54,035
let's look at what happens to the Miss

1386
01:14:49,058 --> 01:15:02,083
rate when we do this so there's there's

1387
01:14:54,035 --> 01:15:07,042
n over B blocks in in any row or column

1388
01:15:02,083 --> 01:15:11,141
and since there's B squared items in

1389
01:15:08,005 --> 01:15:17,059
each block B times B there's B squared

1390
01:15:12,041 --> 01:15:20,850
over eight misses for each block okay

1391
01:15:17,059 --> 01:15:23,105
and so then and then since there's

1392
01:15:21,219 --> 01:15:27,290
there's n over B blocks in each matrix

1393
01:15:24,005 --> 01:15:33,424
and there's two matrices there's 2 - n

1394
01:15:27,029 --> 01:15:35,458
over B times B squared over 8 misses for

1395
01:15:33,469 --> 01:15:41,494
this first iteration so that that works

1396
01:15:35,719 --> 01:15:43,880
out to be an NB divided by 4 and the

1397
01:15:41,719 --> 01:15:47,060
second iteration has the same as the

1398
01:15:43,088 --> 01:15:49,327
same miss sort of same miss rate so that

1399
01:15:47,006 --> 01:15:53,006
the total number of misses is the number

1400
01:15:50,119 --> 01:15:59,152
of the number of misses for each

1401
01:15:53,006 --> 01:16:01,067
iteration x times the number of elements

1402
01:15:59,449 --> 01:16:06,170
and see that we're updating okay which

1403
01:16:01,067 --> 01:16:08,056
is n over B squared so that all works

1404
01:16:06,017 --> 01:16:13,094
out - it's still in its n cube divided

1405
01:16:08,659 --> 01:16:16,684
by 4 B so in our first case with no

1406
01:16:13,094 --> 01:16:19,063
blocking although that the number of

1407
01:16:16,909 --> 01:16:21,913
misses is asymptotically the same but

1408
01:16:19,909 --> 01:16:23,630
there's this pretty this big difference

1409
01:16:21,949 --> 01:16:26,840
in the constant factor so for no

1410
01:16:23,063 --> 01:16:28,154
blocking it's 9 over 8 for blocking it's

1411
01:16:26,084 --> 01:16:32,153
1 over 4b we're now we can we can just

1412
01:16:29,054 --> 01:16:34,082
sort of drive that down by by increasing

1413
01:16:33,053 --> 01:16:40,079
the block size so this gives us some

1414
01:16:34,082 --> 01:16:41,180
some control but we still we have we

1415
01:16:40,079 --> 01:16:43,148
can't make the block the blocks too big

1416
01:16:42,008 --> 01:16:47,104
because we need to fit three blocks in

1417
01:16:44,048 --> 01:16:48,076
the in cash at any one point in time

1418
01:16:49,021 --> 01:16:54,107
okay so the reason this is a dramatic

1419
01:16:51,739 --> 01:16:58,670
difference right and the reason for this

1420
01:16:55,007 --> 01:17:01,052
is that by doing the blocking we're sort

1421
01:16:58,067 --> 01:17:02,132
of exploiting once we load a block into

1422
01:17:01,052 --> 01:17:04,501
memory we're sort of reusing its items

1423
01:17:03,032 --> 01:17:09,061
over and over again so we're exploiting

1424
01:17:04,969 --> 01:17:10,880
more temporal locality and matrix

1425
01:17:09,349 --> 01:17:13,426
multiplication has this into this

1426
01:17:10,088 --> 01:17:15,134
implicit locality because the

1427
01:17:14,119 --> 01:17:20,200
computation is order n cubed but the

1428
01:17:16,034 --> 01:17:23,108
size of the data is N squared and so so

1429
01:17:20,929 --> 01:17:25,760
we must be reusing some data items right

1430
01:17:24,008 --> 01:17:28,027
the problem with our scaler approach is

1431
01:17:25,076 --> 01:17:31,139
that we we were when we were reusing

1432
01:17:28,099 --> 01:17:38,700
them they weren't in the cache okay

1433
01:17:32,039 --> 01:17:40,107
all right so the point that I wanted to

1434
01:17:38,007 --> 01:17:41,088
make with you is that cache memories

1435
01:17:41,007 --> 01:17:45,045
although they're they're sort of

1436
01:17:42,051 --> 01:17:47,148
built-in automatic hardware

1437
01:17:45,045 --> 01:17:51,050
storage devices and you can't really

1438
01:17:48,048 --> 01:17:53,126
control them if you know about them you

1439
01:17:51,005 --> 01:17:56,067
can take advantage of your knowledge and

1440
01:17:54,026 --> 01:17:59,109
exploit exploit them and make your code

1441
01:17:57,012 --> 01:18:04,067
run faster okay and the way you do this

1442
01:18:00,009 --> 01:18:04,067
is like I said focus on the inner loops

1443
01:18:04,007 --> 01:18:11,061
do is try to do try to accesses that our

1444
01:18:08,079 --> 01:18:13,152
stride one and try to maximize to to

1445
01:18:12,024 --> 01:18:17,037
maximize spatial locality and try to

1446
01:18:14,052 --> 01:18:18,105
maximize temporal locality by reusing

1447
01:18:17,037 --> 01:18:22,071
local variables which can then be put

1448
01:18:19,005 --> 01:18:24,066
into registers okay so that's it for

1449
01:18:22,071 --> 01:18:26,133
today good luck with your attack lab if

1450
01:18:24,066 --> 01:18:28,101
you haven't finished it and don't forget

1451
01:18:27,033 --> 01:18:31,037
to get started on cache labs on this

1452
01:18:29,001 --> 01:18:31,037
weekend

